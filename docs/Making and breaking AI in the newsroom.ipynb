{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d7b4c719",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Making and breaking AI in the newsroom\"\n",
    "subtitle: \"iMEdD Forum, Athens 2023\"\n",
    "output-file: \"index.html\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    page-layout: full\n",
    "    embed-resources: false\n",
    "    theme:\n",
    "        - cosmo\n",
    "        - custom.css\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c832057f",
   "metadata": {},
   "source": [
    "Jonathan Soma / [js4571@columbia.edu](mailto:js4571@columbia.edu) / [@dangerscarf](https://twitter.com/dangerscarf/)\n",
    "\n",
    "iMEdD Forum 2023\n",
    "\n",
    "üïπÔ∏è GitHub repo can be found at [https://github.com/jsoma/2023-imedd-ai-workshop](https://github.com/jsoma/2023-imedd-ai-workshop)\n",
    "\n",
    "üíª Run this notebook as a live programming exercise [here on Google Colab](https://colab.research.google.com/github/jsoma/2023-imedd-ai-workshop/blob/main/docs/Making%20and%20breaking%20AI%20in%20the%20newsroom.ipynb). Use `shift+enter` or the ‚ñ∂Ô∏è button to run the code.\n",
    "\n",
    "::: {.callout-note appearance=\"simple\"}\n",
    "\n",
    "This web page was made from a Jupyter notebook! To see how I made it, [see this tutorial about Quarto](https://github.com/jsoma/quarto-tutorial).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d772c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "!wget https://github.com/jsoma/2023-imedd-ai-workshop/raw/main/docs/data-files.zip\n",
    "!unzip data-files.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b3ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "!pip install -q --upgrade transformers openai langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bacd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# You'll need your own OpenAI GPT API key! This one was mine,\n",
    "# but I've deactivated it so I can publish this.\n",
    "API_KEY = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "response = llm.predict(\"Give me a recipe for chocolate-chip cookies\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdbc908",
   "metadata": {},
   "source": [
    "## Headline generation\n",
    "\n",
    "You should do this in ChatGPT! It's much better as a conversation than using a single perfect prompt to get the result you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa70758",
   "metadata": {},
   "source": [
    "## Article summaries\n",
    "\n",
    "Sometimes you need to write little blurbs for articles: maybe for social posts, front pages, or newsletters.\n",
    "\n",
    "Below is a NYTimes article I'm using as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "A few blocks away from where a 1-year-old boy died, possibly from fentanyl poisoning at his Bronx day care this month, an open-air drug market persists along a trash-strewn underpass.\n",
    "\n",
    "On Wednesday, a man on a moped arrived in the late afternoon and about a dozen users ambled over to purchase drugs with dollar bills in their hands. People tied off their arms, prepped needles or packed pipes. After a while, the ground was littered with syringes and bloodstained alcohol swabs.\n",
    "\n",
    "No police officers were seen, although they are often nearby ‚Äî sometimes steps away in the Kingsbridge Road subway station. But they rarely intervene, according to local residents, elected officials who have tried to clean up the area for several years, and nonprofit workers who distribute food and clean needles at the site.\n",
    "\n",
    "Residents and community leaders say they are regularly told by city officials that they are doing their best to make the area safer. But the Kingsbridge Road underpass is just one of many locations in the city where drug use has become more open, even as lives lost to overdoses are at a record high ‚Äî roughly 3,200 such deaths citywide in 2022, according to an annual report by the city‚Äôs special narcotics prosecutor‚Äôs office.\n",
    "\n",
    "The situation there underscores an increasingly difficult dilemma for the city: how to curb an epidemic killing thousands of New Yorkers and making neighborhoods feel unlivable for thousands of others, without reverting to aggressive crackdowns, which many leaders and public health experts said have led to civil rights abuses and did not effectively curb drug use.\n",
    "\n",
    "The stakes are especially high with fentanyl, an extremely potent drug whose street version is becoming ever deadlier. It can kill a child if even a tiny amount is accidentally swallowed.\n",
    "\n",
    "Areas of the city where drug use is often in plain view range from lower-income and working class areas like the Hub at 149th Street in the Bronx, to busy tourist-filled spots like Times Square and parts of the West Village. Other cities, like Portland, Ore., and Phoenix, are grappling with similar problems.\n",
    "\n",
    "‚ÄúThe kids have to walk by it every day, exposed at a young age to very graphic scenes,‚Äù said Carol Rodriguez, 39, who was walking not far from the Kingsbridge underpass on her way to get her 9-year-old from school. She said things had deteriorated since the pandemic. ‚ÄúI worry that they grow up thinking this is normal.‚Äù\n",
    "\n",
    "Tolerating low-level dealing also represents a broader threat beyond the public health crisis, some former law enforcement officials warn, because violence can follow, and because it makes it harder to find and prosecute those higher up the chain.\n",
    "\n",
    "In the meantime, the question of how to avoid the collateral damage of drug use has only grown more urgent: Opioids have become the leading cause of child poisonings in the United States. More than 1,500 children died in fatal overdoses involving fentanyl in 2021, according to one study; over 100 were children under the age of 4.\n",
    "\n",
    "Officials have not confirmed whether fentanyl was the cause of death for Nicholas Feliz Dominici, the 1-year-old who died in the Bronx on Sept. 15, but three other children from the same day care were hospitalized that day after they were exposed to fentanyl. Days after the child died, the police discovered a trap door under a play area concealing large, clear storage bags filled with narcotics. The day care‚Äôs operator and a man who lived in the apartment that housed the day care have been arrested and charged with murder and criminal drug possession.\n",
    "\n",
    "The rising death toll comes as the city and the state have turned away from the aggressive law enforcement of low-level street drug activity that was common in the late 1990s. The shift has happened gradually over time, as a broader movement has pushed to reframe drug use as a public health crisis rather than as primarily a criminal issue.\n",
    "\n",
    "New York City, for example, has the only city-sanctioned drug consumption sites in the nation, in East Harlem and Washington Heights, where people can use drugs under the supervision of trained workers who prevent overdoses while offering treatment to those who ask for it.\n",
    "\n",
    "Proponents of this path say that criminalization has not worked, and has clearly not led to the elimination of drugs from our society. Rather, they say, it just pushes the problem out of view, and makes it harder for users to get help.\n",
    "\n",
    "‚ÄúThe thing I refuse to do is say that the way to solve the problem is to throw more police at it,‚Äù said Gustavo Rivera, a state senator representing the Bronx, who has introduced a bill supporting decriminalization of all drugs. ‚ÄúWe have to have a comprehensive approach.‚Äù\n",
    "\n",
    "He added that if there was an overdose prevention center near the underpass, ‚Äúyou would not have those folks there. They would be in a non-stigmatized place, able to access services.‚Äù\n",
    "\n",
    "There have been several forks in the road that have led more public officials to think the same way.\n",
    "\n",
    "The so-called War on Drugs in the 1970s and 1980s aimed for a zero-tolerance approach. But it also led to the incarceration of millions of Black and Latino people across the country, often for nonviolent offenses. While the overall number of cocaine users declined during those years, the amount of drugs consumed stayed the same and the number of teenagers who tried illicit drugs rose, according to one study by the RAND Corporation.\n",
    "\n",
    "In response, New York passed laws to address civil rights concerns, including one in 2019 that, among other things, significantly increased the amount of paperwork that had to be done after drug arrests, and gave prosecutors a shorter time frame to hand evidence over to the accused.\n",
    "\n",
    "In 2021, Gov. Kathy Hochul signed a law that decriminalized the sale and possession of hypodermic needles, and also expanded the number of crimes in which those charged were eligible for diversion to drug treatment programs instead of prison. It was another signal to law enforcement that while possessing a small quantity of illegal drugs remains a crime ‚Äî street use, in some ways, had essentially been decriminalized.\n",
    "\n",
    "State bail reform laws, also passed in 2019, have allowed more people accused of crimes to return to the community shortly after their arrests. Whether this has actually increased crime is not clear, but even so, experts said the police are less likely to act aggressively if they know the people they arrest will be back on the street shortly afterward.\n",
    "\n",
    "Bridget Brennan, the city‚Äôs special narcotics prosecutor, said that while the new laws were intended to reduce overdoses and reverse decades of harsh prison sentences for lower-level offenses, they also had the unintended effect of emboldening drug dealers. She said prosecutors will charge dealers three or four times and they still will not be held on bail.\n",
    "\n",
    "‚ÄúWhat that means in terms of drug dealers is they‚Äôre going to be more bold and blatant in their activity,‚Äù she said. ‚ÄúThere is a lot of money to be made and there is not much of a deterrent.‚Äù\n",
    "\n",
    "The number of narcotics arrests in the city closely tracks the policy shift. There were 27,232 narcotics arrests in 2018, according to police data. That dropped to 14,156 in 2020, at the height of the pandemic. Narcotics arrests for 2023 have risen, to 16,000 as of Sept. 17, a 34 percent increase from the same time period last year, but they remain well below 2018 levels.\n",
    "\n",
    "Joseph Kenny, the chief of detectives for the Police Department, said that arresting a person for having a needle ‚Äúwas never a priority in our world.‚Äù\n",
    "\n",
    "‚ÄúWe are not looking to take drug abusers and put them in prison,‚Äù Chief Kenny said. ‚ÄúWe want them to get the help they need.‚Äù\n",
    "\n",
    "As for arresting low-level street dealers, he said, prosecutors ‚Äúare asking us to build bigger cases.‚Äù\n",
    "\n",
    "‚ÄúWe need to target the dealers, the suppliers and the traffickers,‚Äù Chief Kenny said.\n",
    "\n",
    "Civil rights concerns animate those opposed to more crackdowns; 94 percent of those prosecuted for narcotics charges in the Bronx were Black or Latino.\n",
    "\n",
    "Supporters of decriminalization also point to data showing the lives saved at supervised consumption sites. Some express frustration that despite outward support by public officials, the centers still often exist in a legal purgatory, illegal under federal law, and lack government funding that might allow them to expand. Opponents say the sites encourage more drug use, especially on the blocks nearby.\n",
    "\n",
    "Dr. Andrea Littleton provides medical care to drug users at the Kingsbridge underpass. She favors decriminalization, because she hopes that would lead to more regulation, and ‚Äúhopefully get some of the fentanyl off the street.‚Äù\n",
    "\n",
    "‚ÄúAt least then it would be less deadly to individuals, to babies and day cares,‚Äù she said.\n",
    "\n",
    "One of the biggest concentrations of street drug activity in the city is near 125th Street and Lexington Ave in Harlem, near some drug treatment clinics. On one Wednesday in August, four officers stood on the southwest corner of the street, two of them looking at their phones.\n",
    "\n",
    "When approached by a reporter, they said they had been told to stand there.\n",
    "\n",
    "At one point, a different pair of police officers approached a busy corner for street drug activity ‚Äî to give a summons to a man for public drinking.\n",
    "\n",
    "Shawn Hill, co-founder of the Greater Harlem Coalition, a community group, has spent dozens of hours documenting open drug activity in the neighborhood in the hopes of reducing it. He seldom spots an arrest, he said.\n",
    "\n",
    "‚ÄúI think policing has changed dramatically in the last four or five years,‚Äù he said.\n",
    "\n",
    "In a statement, the Police Department called the issue ‚Äúa real concern to residents in all city neighborhoods.‚Äù\n",
    "\n",
    "‚ÄúThere‚Äôs still work to be done, but our officers are more engaged and focused than ever,‚Äù the statement said.\n",
    "\n",
    "Narcotics squads are still making thousands of arrests, including high-level drug busts, which are often undertaken with federal law enforcement. To underscore the risks of fentanyl after last week‚Äôs day care death, the city on Wednesday held a news conference to announce a large guns and drugs bust in Queens.\n",
    "\n",
    "Ms. Brennan said that last year, her office seized about 1,000 pounds of fentanyl off the street and about one million pills. Police officials said an additional 150 officers have been added to narcotics squads recently, with plans for more. Each borough has two teams of officers assigned to investigate 911 and 311 calls about drug-related complaints. Additional units conduct ‚Äúbuy and bust‚Äù operations, where undercover officers make multiple drug buys from the same dealer in order to catch the more prolific street-level dealers.\n",
    "\n",
    "‚ÄúOur goal is that citizens shouldn‚Äôt have to walk past a drug dealer to get into their building,‚Äù Chief Kenny said.\n",
    "\n",
    "Yet in some pockets, like Kingsbridge, several residents said it feels so unsafe that they have stopped leaving the house after 6 p.m. ‚ÄúYou‚Äôll come down the stairs with the kids in the morning and there‚Äôs someone sitting there, just shooting up,‚Äù said Chris Castellanos, 35, a father of four children.\n",
    "\n",
    "Karla Cabrera Carrera, the district manager of Community Board 7, which includes Kingsbridge, said that society has to think about the rights of residents to feel secure, too.\n",
    "\n",
    "‚ÄúWe are really facing a really bad issue,‚Äù she said. ‚ÄúI love the Bronx, I don‚Äôt want to have to move, but at this point, we are all desperate to find a solution to all of it.‚Äù\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c56e1b",
   "metadata": {},
   "source": [
    "I put together a template that we can use to send the article to GPT. The `{text}` part gets filled in with whatever we want - in this case it's the article, but we'll expand on this in other directions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb59b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Summarize the article below:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=\"This fills in the blank\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c13a2",
   "metadata": {},
   "source": [
    "Now let's do all of the steps:\n",
    "\n",
    "1. Connect to GPT\n",
    "2. Create our prompt\n",
    "3. Send it over\n",
    "\n",
    "Note that if you get an error, make sure you're run the cell above that creates the article! You need to click it and shift+enter, or press the \"Run\" button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531bab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# You'll need your own OpenAI GPT API key! This one was mine,\n",
    "# but I've deactivated it so I can publish this.\n",
    "API_KEY = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957721b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Summarize the article below:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=article)\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c1b24",
   "metadata": {},
   "source": [
    "This gets us an answer, but *can we write a better prompt?*\n",
    "\n",
    "Think about asking GPT to use a specific tone, or cheat a little by telling it to copy a publication. You can also set a length, reading level or target audience!\n",
    "\n",
    "I also recommend asking your tools for suggestions ‚Äì you can try asking ChatGPT \"how would you describe the writing style of the New York Times? Be detailed.\" and use that as a jumping-off point.\n",
    "\n",
    "> Don't ever feel like your prompt is too long! Check the [EditorBot prompt](https://jamditis.notion.site/Superprompt-EditorBot-for-feedback-on-your-writing-0268051a8f384762a2686b1d43ad390b) - it's approximately ten million words long! You can always refine it later if you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Summarize the article below:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=article)\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5971e7",
   "metadata": {},
   "source": [
    "## Document summaries (research)\n",
    "\n",
    "### Text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a750d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll add this later!\n",
    "# You don't normally have text files, do you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda1140",
   "metadata": {},
   "source": [
    "### PDF\n",
    "\n",
    "PDFs are common sources for longer documents - reports, academic papers, etc.\n",
    "\n",
    "I like using [pdfminer.six](https://pdfminersix.readthedocs.io/en/latest/) to extract text from PDFs, it's super time. We'll first pull the text out, then try to send it to GPT for a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f94b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "pdf_text = extract_text(\"data-files/ai-report.pdf\")\n",
    "print(pdf_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6639b13a",
   "metadata": {},
   "source": [
    "Now let's use a simple summarization prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14948065",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Summarize the paper below:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=pdf_text)\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a4de86",
   "metadata": {},
   "source": [
    "**We get an error!** This is because our text is longer than GPT's **token limit.**\n",
    "\n",
    "To make this summarization work, we have to **split our document into pieces!**\n",
    "\n",
    "> Instead of the AI report, I'm also going to shift to using a slightly shorter academic paper! The AI report gets broken into about 90 pieces which takes a while to process. The science paper is only a *little* long, so it's just 21 segments.\n",
    ">\n",
    "> If you'd like to try the AI report (and wait a while in the process), feel free to change the filename.\n",
    "\n",
    "We'll start by reading in our document, and using `load_and_split` to divide it up into separate pages. Later on we'll show an example of a more \"intelligent\" splitting that understands headers and sections, but this one is a simple example for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff63d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('data-files/science-paper.pdf')\n",
    "docs = loader.load_and_split()\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd6389",
   "metadata": {},
   "source": [
    "Then we'll connect to GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# You'll need your own OpenAI GPT API key! This one was mine,\n",
    "# but I've deactivated it so I can publish this.\n",
    "API_KEY = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8529ce4",
   "metadata": {},
   "source": [
    "Finally, we'll create a prompt to summarize the pieces. It's a lot of code, but I promise you'll (almost???) always use the same one every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "prompt_template = \"\"\"Summarize the following document.\n",
    "\n",
    "\n",
    "TEXT: {text}\n",
    "\n",
    "\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "chain = load_summarize_chain(llm,\n",
    "                             chain_type=\"map_reduce\",\n",
    "                             return_intermediate_steps=True,\n",
    "                             map_prompt=PROMPT,\n",
    "                             combine_prompt=PROMPT)\n",
    "\n",
    "result = chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd28eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd364b",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "While we *could* use something like DeepL or Google Translate, why not just use the LLM for *absolutely everything?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folktale = open(\"data-files/folktale-short.txt\").read()\n",
    "print(folktale[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425632b",
   "metadata": {},
   "source": [
    "Like always, we'll start by connecting to ChatGPT, build a prompt, then send it over to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# You'll need your own OpenAI GPT API key! This one was mine,\n",
    "# but I've deactivated it so I can publish this.\n",
    "API_KEY = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "template = \"\"\"\n",
    "Translate the text below into English:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=folktale)\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a8756",
   "metadata": {},
   "source": [
    "What happens if we try with `gpt-4` instead of `gpt-3.5-turbo`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# You'll need your own OpenAI GPT API key! This one was mine,\n",
    "# but I've deactivated it so I can publish this.\n",
    "API_KEY = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-4\")\n",
    "\n",
    "template = \"\"\"\n",
    "Translate the text below into English:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=folktale)\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff9c71",
   "metadata": {},
   "source": [
    "## Transcription (speech to text)\n",
    "\n",
    "[Whisper](https://github.com/openai/whisper) is a transcription engine. You can use the code below to read from an mp3, or you can [try the interactive version](https://huggingface.co/spaces/openai/whisper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1883a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"data-files/sample-audio.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"text\"][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46859531",
   "metadata": {},
   "source": [
    "In the example above, we use the `base` model. You can see [the different model versions here](https://github.com/openai/whisper#available-models-and-languages), which vary in their accuracy and knowledge of non-English languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51b4ff6",
   "metadata": {},
   "source": [
    "## Reading text out loud (text to speech)\n",
    "\n",
    "[Text to speech models on HuggingFace](https://huggingface.co/models?pipeline_tag=text-to-speech&sort=trending). They... are mostly not that good. Usually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e52b20",
   "metadata": {},
   "source": [
    "### Voice cloning\n",
    "\n",
    "I'm just going to send you to [ElevenLabs](https://elevenlabs.io/). I showed you an example in class, but I don't have an interactive one here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656b358",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "\n",
    "### Zero-shot classification\n",
    "\n",
    "Because large language models are remarkably well-read, they're very good at categorizing content for you. If your categories are nuanced and specific it's a little more trouble, but if you're categorizing content across *broad categories* it should do a great job.\n",
    "\n",
    "Here's a basic example of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1add4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Categorize the following text as being about ENVIRONMENT, GUN CONTROL,\n",
    "or IMMIGRATION. Respond with only the category.\n",
    "\n",
    "Text: A Bill to Regulate the Sulfur Emissions of Coal-Fired Energy\n",
    "Plants in the State of New York.\n",
    "\"\"\"\n",
    "\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b27cb8",
   "metadata": {},
   "source": [
    "Instead of writing the big long `\"Categorize the following text...\"` prompt for *every single bill*, we can also use Python's `.format`. It allows us to write the prompt once, then fill in the blanks for the part that changes each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fcd111",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Categorize the following text as being about ENVIRONMENT, GUN CONTROL,\n",
    "or IMMIGRATION. Respond with only the category.\n",
    "\n",
    "Text: {bill_text}\n",
    "\"\"\"\n",
    "\n",
    "print(template.format(bill_text=\"This fills in the spot in the template\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582fc20a",
   "metadata": {},
   "source": [
    "This is super convenient if we want to categorize many things! For example, you might use a loop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82c9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Categorize the following text as being about ENVIRONMENT, GUN CONTROL,\n",
    "or IMMIGRATION. Respond with only the category.\n",
    "\n",
    "Text: {bill_text}\n",
    "\"\"\"\n",
    "\n",
    "bills = [\n",
    "    \"A Bill to Allow Additional Refugees In Upstate New York\",\n",
    "    \"A Bill to Close Down Coal-fired Power Plants\",\n",
    "    \"A Bill to Banning Assault Rifles at Public Events\"\n",
    "]\n",
    "\n",
    "for bill in bills:\n",
    "    prompt = template.format(bill_text=bill)\n",
    "    response = llm.predict(prompt)\n",
    "    print(bill, \"is\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a2468",
   "metadata": {},
   "source": [
    "...or if you have a pandas DataFrame, you can use `.apply` and build a new column for your category!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4dc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 500)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'title': [\n",
    "        \"A Bill to Allow Additional Refugees In Upstate New York\",\n",
    "        \"A Bill to Close Down Coal-fired Power Plants\",\n",
    "        \"A Bill to Banning Assault Rifles at Public Events\"\n",
    "    ]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Categorize the following text as being about ENVIRONMENT, GUN CONTROL,\n",
    "or IMMIGRATION. Respond with only the category.\n",
    "\n",
    "Text: {bill_text}\n",
    "\"\"\"\n",
    "\n",
    "def make_prediction(row):\n",
    "    text = row['title']\n",
    "    prompt = template.format(bill_text=text)\n",
    "    response = llm.predict(prompt)\n",
    "    return response\n",
    "\n",
    "# Send each row to make_prediction and store the category in a new column\n",
    "df['predicted_category'] = df.apply(make_prediction, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e9c10a",
   "metadata": {},
   "source": [
    "It's like magic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933749b0",
   "metadata": {},
   "source": [
    "### GPT in Google Sheets\n",
    "\n",
    "You can also do this with GPT [in Google Sheets](https://www.makeuseof.com/how-use-chatgpt-google-sheets/) instead of relying on code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a082e",
   "metadata": {},
   "source": [
    "### Few-shot classification\n",
    "\n",
    "Sometimes your classifier might not do a great job. It might be a topic the LLM doesn't know much about, you might be asking for nuance it doesn't have out of the box, or a million and one other things might be going wrong. In those cases, it's useful to try **few-shot classification**.\n",
    "\n",
    "In the same way that zero-shot classification takes zero examples going in, few-shot classification takes... a few examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Categorize the following text as being about ENVIRONMENT, GUN CONTROL,\n",
    "or IMMIGRATION. Respond with only the category.\n",
    "\n",
    "Text: Something about immigration\n",
    "IMMIGRATION\n",
    "\n",
    "Text: Something about gun control\n",
    "GUN CONTROL\n",
    "\n",
    "Text: {bill_text}\n",
    "\"\"\"\n",
    "\n",
    "print(template.format(bill_text=\"This fills in the spot in the template\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8042f4",
   "metadata": {},
   "source": [
    "### Custom classifiers\n",
    "\n",
    "You can also use [Hugging Face AutoTrain](https://ui.autotrain.huggingface.co/) to train your own classifiers. Instead of trusting that the model has enough information about the world to make a decision, you give it exactly what it needs to know.\n",
    "\n",
    "They aren't necessarily worse or better: they're just more work on your end because you have to manually label each category to show it what you mean. Instead of \"few shot\" it's \"a whole lot of shots\" - probably hundreds!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c689d",
   "metadata": {},
   "source": [
    "## Format shifting\n",
    "\n",
    "A lot of the power of these models involves format shifting, changing from one format to another. Audio, text, images, video.\n",
    "\n",
    "* **Video to image:** then analyze the images\n",
    "* **Audio to text:** transcription\n",
    "* **Text to image:** I think this one is immoral. Art is resistant to errors, so it's much easier to just rip off someone's style. It's also trained on peoples' work in a way that's far more obviously inappropriate than text models.\n",
    "* **Image to text:** accessibility and research\n",
    "\n",
    "If you have a lot of content in one category, it's worth thinking about what you can do to convert it into another category and re-use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa5b84",
   "metadata": {},
   "source": [
    "## Image models\n",
    "\n",
    "The three major things you can do with images is:\n",
    "\n",
    "1. Categorize your images\n",
    "2. Detect objects in the images\n",
    "3. Separate your image into pieces (pixel counting)\n",
    "\n",
    "If you use [HuggingFace AutoTrain](https://ui.autotrain.huggingface.co/), you can easily make your own models! I made one [to classify illegal amber mines](https://huggingface.co/wendys-llc/amber-mines) based on [Texty's work](https://texty.org.ua/d/2018/amber_eng/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71de518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"image-classification\", model=\"wendys-llc/amber-mines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4c0164",
   "metadata": {},
   "source": [
    "What does the model think about this image?\n",
    "\n",
    "![](amber-sample-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ce1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\"amber-sample-1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5870a",
   "metadata": {},
   "source": [
    "How about this one?\n",
    "\n",
    "![](amber-sample-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\"amber-sample-2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91b830",
   "metadata": {},
   "source": [
    "### Object detection\n",
    "\n",
    "[Here is an example of object detection](https://huggingface.co/spaces/wendys-llc/OWL-ViT)\n",
    "\n",
    "You can combine this with a large language model to ask questions of images. \"Are there cats in this image?\" It's like a more flexible classifier ‚Äì but with limitations about what the model knows about.\n",
    "\n",
    "### Semantic segmentation\n",
    "\n",
    "[Here is an example of semantic segmentation](https://huggingface.co/spaces/thiagohersan/maskformer-satellite-trees-gradio)\n",
    "\n",
    "How much of this image is pavement? Or grass? Or trees? Or cars?\n",
    "\n",
    "Not too useful with normal imagery, but very useful for satellite or aerial imagery.\n",
    "\n",
    "### Panoptic segmentation\n",
    "\n",
    "[Here is an example of panoptic segmentation](https://huggingface.co/spaces/wendys-llc/panoptic-segment-anything)\n",
    "\n",
    "Panoptic segmentation does both object detection *and* semantic segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c1ab96",
   "metadata": {},
   "source": [
    "## Semantic search\n",
    "\n",
    "A combination of semantic search and keyword matching usually outperforms semantic search by itself.\n",
    "\n",
    "Transcribing all of your interviews and then doing searches across them is a beautiful thing.\n",
    "\n",
    "Give [Semantra](https://github.com/freedmand/semantra) a try to run it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e68747",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc552e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentences = [\n",
    "    \"Molly ate a fish\",\n",
    "    \"Jen consumed a carp\",\n",
    "    \"I would like to sell you a house\",\n",
    "    \"–Ø –ø—ã—Ç–∞—é—Å—å –∫—É–ø–∏—Ç—å –¥–∞—á—É\", # I'm trying to buy a summer home\n",
    "    \"J'aimerais vous louer un grand appartement\", # I would like to rent a large apartment to you\n",
    "    \"This is a wonderful investment opportunity\",\n",
    "    \"–≠—Ç–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π\", # investment opportunity\n",
    "    \"C'est une merveilleuse opportunit√© d'investissement\", # investment opportunity\n",
    "    \"„Åì„Çå„ÅØÁ¥†Êô¥„Çâ„Åó„ÅÑÊäïË≥áÊ©ü‰ºö„Åß„Åô\", # investment opportunity\n",
    "    \"ÈáéÁêÉ„ÅØ„ÅÇ„Å™„Åü„ÅåÊÄù„ÅÜ„Çà„Çä„ÇÇÈù¢ÁôΩ„ÅÑ„Åì„Å®„Åå„ÅÇ„Çä„Åæ„Åô\", # baseball can be more interesting than you think\n",
    "    \"Baseball can be interesting than you'd think\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute similarities exactly the same as we did before!\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "# Turn into a dataframe\n",
    "pd.DataFrame(similarities,\n",
    "            index=sentences,\n",
    "            columns=sentences) \\\n",
    "            .style \\\n",
    "            .background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a410d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute similarities exactly the same as we did before!\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "# Turn into a dataframe\n",
    "pd.DataFrame(similarities,\n",
    "            index=sentences,\n",
    "            columns=sentences) \\\n",
    "            .style \\\n",
    "            .background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81cda8a",
   "metadata": {},
   "source": [
    "### Searching through documents with semantic search\n",
    "\n",
    "What does this allow you to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df46499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('ai-report.pdf')\n",
    "docs = loader.load_and_split()\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e758e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name='paraphrase-multilingual-MiniLM-L12-v2')\n",
    "db = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search(\"losing jobs\", k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e840d85",
   "metadata": {},
   "source": [
    "### Specifying details\n",
    "\n",
    "Let's get a little more specific!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader('hungarian-folktales.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name='paraphrase-multilingual-MiniLM-L12-v2')\n",
    "db = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0c000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = db.similarity_search(\"weddings at a festival with loud music\", k=1)\n",
    "\n",
    "for match in matches:\n",
    "    print(match.page_content)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f3b39",
   "metadata": {},
   "source": [
    "## Retrieval-augmented generation (smart chatbots)\n",
    "\n",
    "Find relevant passages, send them to your chatbot along with your question.\n",
    "\n",
    "::: {.callout-note appearance=\"simple\"}\n",
    "You can improve performance by generating potential answers, then also including things similar to potential answers.\n",
    ":::\n",
    "\n",
    "There are a lot of places things can go wrong: segmented poorly or missing context, non-useful embeddings, question not being answered incorrectly. It's probably best if you just use semantic search to get results and read them yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d12d447",
   "metadata": {},
   "source": [
    "## Expanding your skillset\n",
    "\n",
    "Lorem ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bfb55e",
   "metadata": {},
   "source": [
    "## Contact me\n",
    "\n",
    "Feel free to reach out ‚Äì I'm more than happy to provide ideas, guidance, lectures, etc etc etc. You can find me via email at [js4571@columbia.edu](mailto:js4571@columbia.edu) or on Twitter at [@dangerscarf](https://twitter.com/dangerscarf). I also run two data journalism programs at Columbia: the 12-month [Data Journalism MS](https://journalism.columbia.edu/ms-data-journalism) and the [Lede Program](https://ledeprogram.com/), a summer intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3316b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
