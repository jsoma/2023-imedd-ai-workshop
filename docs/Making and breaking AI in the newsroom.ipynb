{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d7b4c719",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Making and breaking AI in the newsroom\"\n",
    "subtitle: \"iMEdD Forum, Athens 2023\"\n",
    "output-file: \"index.html\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    page-layout: full\n",
    "    embed-resources: false\n",
    "    theme:\n",
    "        - cosmo\n",
    "        - custom.css\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a447f3f",
   "metadata": {},
   "source": [
    "Jonathan Soma / [js4571@columbia.edu](mailto:js4571@columbia.edu) / [@dangerscarf](https://twitter.com/dangerscarf/)\n",
    "\n",
    "iMEdD Forum 2023\n",
    "\n",
    "üïπÔ∏è GitHub repo can be found at [https://github.com/jsoma/2023-imedd-ai-workshop](https://github.com/jsoma/2023-imedd-ai-workshop)\n",
    "\n",
    "üíª Run this notebook as a live programming exercise [here on Google Colab](https://colab.research.google.com/github/jsoma/2023-imedd-ai-workshop/blob/main/docs/Making%20and%20breaking%AI%20in%20the%20newsroom.ipynb). Use `shift+enter` or the ‚ñ∂Ô∏è button to run the code.\n",
    "\n",
    "::: {.callout-note appearance=\"simple\"}\n",
    "\n",
    "This web page was made from a Jupyter notebook! To see how I made it, [see this tutorial about Quarto](https://github.com/jsoma/quarto-tutorial).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "!wget ai-report.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b917678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "!pip install -q --upgrade transformers openai langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# You'll need your own OpenAI GPT API key! This one was mine,\n",
    "# but I've deactivated it so I can publish this.\n",
    "API_KEY = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "response = llm.predict(\"Give me a recipe for chocolate-chip cookies\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7f258",
   "metadata": {},
   "source": [
    "## Headline generation\n",
    "\n",
    "You should do this in ChatGPT! It's much better as a conversation than using a single perfect prompt to get the result you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e7953",
   "metadata": {},
   "source": [
    "## Article summaries\n",
    "\n",
    "Sometimes you need to write little blurbs for articles: maybe for social posts, front pages, or newsletters.\n",
    "\n",
    "Below is a NYTimes article I'm using as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7da56fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "A few blocks away from where a 1-year-old boy died, possibly from fentanyl poisoning at his Bronx day care this month, an open-air drug market persists along a trash-strewn underpass.\n",
    "\n",
    "On Wednesday, a man on a moped arrived in the late afternoon and about a dozen users ambled over to purchase drugs with dollar bills in their hands. People tied off their arms, prepped needles or packed pipes. After a while, the ground was littered with syringes and bloodstained alcohol swabs.\n",
    "\n",
    "No police officers were seen, although they are often nearby ‚Äî sometimes steps away in the Kingsbridge Road subway station. But they rarely intervene, according to local residents, elected officials who have tried to clean up the area for several years, and nonprofit workers who distribute food and clean needles at the site.\n",
    "\n",
    "Residents and community leaders say they are regularly told by city officials that they are doing their best to make the area safer. But the Kingsbridge Road underpass is just one of many locations in the city where drug use has become more open, even as lives lost to overdoses are at a record high ‚Äî roughly 3,200 such deaths citywide in 2022, according to an annual report by the city‚Äôs special narcotics prosecutor‚Äôs office.\n",
    "\n",
    "The situation there underscores an increasingly difficult dilemma for the city: how to curb an epidemic killing thousands of New Yorkers and making neighborhoods feel unlivable for thousands of others, without reverting to aggressive crackdowns, which many leaders and public health experts said have led to civil rights abuses and did not effectively curb drug use.\n",
    "\n",
    "The stakes are especially high with fentanyl, an extremely potent drug whose street version is becoming ever deadlier. It can kill a child if even a tiny amount is accidentally swallowed.\n",
    "\n",
    "Areas of the city where drug use is often in plain view range from lower-income and working class areas like the Hub at 149th Street in the Bronx, to busy tourist-filled spots like Times Square and parts of the West Village. Other cities, like Portland, Ore., and Phoenix, are grappling with similar problems.\n",
    "\n",
    "‚ÄúThe kids have to walk by it every day, exposed at a young age to very graphic scenes,‚Äù said Carol Rodriguez, 39, who was walking not far from the Kingsbridge underpass on her way to get her 9-year-old from school. She said things had deteriorated since the pandemic. ‚ÄúI worry that they grow up thinking this is normal.‚Äù\n",
    "\n",
    "Tolerating low-level dealing also represents a broader threat beyond the public health crisis, some former law enforcement officials warn, because violence can follow, and because it makes it harder to find and prosecute those higher up the chain.\n",
    "\n",
    "In the meantime, the question of how to avoid the collateral damage of drug use has only grown more urgent: Opioids have become the leading cause of child poisonings in the United States. More than 1,500 children died in fatal overdoses involving fentanyl in 2021, according to one study; over 100 were children under the age of 4.\n",
    "\n",
    "Officials have not confirmed whether fentanyl was the cause of death for Nicholas Feliz Dominici, the 1-year-old who died in the Bronx on Sept. 15, but three other children from the same day care were hospitalized that day after they were exposed to fentanyl. Days after the child died, the police discovered a trap door under a play area concealing large, clear storage bags filled with narcotics. The day care‚Äôs operator and a man who lived in the apartment that housed the day care have been arrested and charged with murder and criminal drug possession.\n",
    "\n",
    "The rising death toll comes as the city and the state have turned away from the aggressive law enforcement of low-level street drug activity that was common in the late 1990s. The shift has happened gradually over time, as a broader movement has pushed to reframe drug use as a public health crisis rather than as primarily a criminal issue.\n",
    "\n",
    "New York City, for example, has the only city-sanctioned drug consumption sites in the nation, in East Harlem and Washington Heights, where people can use drugs under the supervision of trained workers who prevent overdoses while offering treatment to those who ask for it.\n",
    "\n",
    "Proponents of this path say that criminalization has not worked, and has clearly not led to the elimination of drugs from our society. Rather, they say, it just pushes the problem out of view, and makes it harder for users to get help.\n",
    "\n",
    "‚ÄúThe thing I refuse to do is say that the way to solve the problem is to throw more police at it,‚Äù said Gustavo Rivera, a state senator representing the Bronx, who has introduced a bill supporting decriminalization of all drugs. ‚ÄúWe have to have a comprehensive approach.‚Äù\n",
    "\n",
    "He added that if there was an overdose prevention center near the underpass, ‚Äúyou would not have those folks there. They would be in a non-stigmatized place, able to access services.‚Äù\n",
    "\n",
    "There have been several forks in the road that have led more public officials to think the same way.\n",
    "\n",
    "The so-called War on Drugs in the 1970s and 1980s aimed for a zero-tolerance approach. But it also led to the incarceration of millions of Black and Latino people across the country, often for nonviolent offenses. While the overall number of cocaine users declined during those years, the amount of drugs consumed stayed the same and the number of teenagers who tried illicit drugs rose, according to one study by the RAND Corporation.\n",
    "\n",
    "In response, New York passed laws to address civil rights concerns, including one in 2019 that, among other things, significantly increased the amount of paperwork that had to be done after drug arrests, and gave prosecutors a shorter time frame to hand evidence over to the accused.\n",
    "\n",
    "In 2021, Gov. Kathy Hochul signed a law that decriminalized the sale and possession of hypodermic needles, and also expanded the number of crimes in which those charged were eligible for diversion to drug treatment programs instead of prison. It was another signal to law enforcement that while possessing a small quantity of illegal drugs remains a crime ‚Äî street use, in some ways, had essentially been decriminalized.\n",
    "\n",
    "State bail reform laws, also passed in 2019, have allowed more people accused of crimes to return to the community shortly after their arrests. Whether this has actually increased crime is not clear, but even so, experts said the police are less likely to act aggressively if they know the people they arrest will be back on the street shortly afterward.\n",
    "\n",
    "Bridget Brennan, the city‚Äôs special narcotics prosecutor, said that while the new laws were intended to reduce overdoses and reverse decades of harsh prison sentences for lower-level offenses, they also had the unintended effect of emboldening drug dealers. She said prosecutors will charge dealers three or four times and they still will not be held on bail.\n",
    "\n",
    "‚ÄúWhat that means in terms of drug dealers is they‚Äôre going to be more bold and blatant in their activity,‚Äù she said. ‚ÄúThere is a lot of money to be made and there is not much of a deterrent.‚Äù\n",
    "\n",
    "The number of narcotics arrests in the city closely tracks the policy shift. There were 27,232 narcotics arrests in 2018, according to police data. That dropped to 14,156 in 2020, at the height of the pandemic. Narcotics arrests for 2023 have risen, to 16,000 as of Sept. 17, a 34 percent increase from the same time period last year, but they remain well below 2018 levels.\n",
    "\n",
    "Joseph Kenny, the chief of detectives for the Police Department, said that arresting a person for having a needle ‚Äúwas never a priority in our world.‚Äù\n",
    "\n",
    "‚ÄúWe are not looking to take drug abusers and put them in prison,‚Äù Chief Kenny said. ‚ÄúWe want them to get the help they need.‚Äù\n",
    "\n",
    "As for arresting low-level street dealers, he said, prosecutors ‚Äúare asking us to build bigger cases.‚Äù\n",
    "\n",
    "‚ÄúWe need to target the dealers, the suppliers and the traffickers,‚Äù Chief Kenny said.\n",
    "\n",
    "Civil rights concerns animate those opposed to more crackdowns; 94 percent of those prosecuted for narcotics charges in the Bronx were Black or Latino.\n",
    "\n",
    "Supporters of decriminalization also point to data showing the lives saved at supervised consumption sites. Some express frustration that despite outward support by public officials, the centers still often exist in a legal purgatory, illegal under federal law, and lack government funding that might allow them to expand. Opponents say the sites encourage more drug use, especially on the blocks nearby.\n",
    "\n",
    "Dr. Andrea Littleton provides medical care to drug users at the Kingsbridge underpass. She favors decriminalization, because she hopes that would lead to more regulation, and ‚Äúhopefully get some of the fentanyl off the street.‚Äù\n",
    "\n",
    "‚ÄúAt least then it would be less deadly to individuals, to babies and day cares,‚Äù she said.\n",
    "\n",
    "One of the biggest concentrations of street drug activity in the city is near 125th Street and Lexington Ave in Harlem, near some drug treatment clinics. On one Wednesday in August, four officers stood on the southwest corner of the street, two of them looking at their phones.\n",
    "\n",
    "When approached by a reporter, they said they had been told to stand there.\n",
    "\n",
    "At one point, a different pair of police officers approached a busy corner for street drug activity ‚Äî to give a summons to a man for public drinking.\n",
    "\n",
    "Shawn Hill, co-founder of the Greater Harlem Coalition, a community group, has spent dozens of hours documenting open drug activity in the neighborhood in the hopes of reducing it. He seldom spots an arrest, he said.\n",
    "\n",
    "‚ÄúI think policing has changed dramatically in the last four or five years,‚Äù he said.\n",
    "\n",
    "In a statement, the Police Department called the issue ‚Äúa real concern to residents in all city neighborhoods.‚Äù\n",
    "\n",
    "‚ÄúThere‚Äôs still work to be done, but our officers are more engaged and focused than ever,‚Äù the statement said.\n",
    "\n",
    "Narcotics squads are still making thousands of arrests, including high-level drug busts, which are often undertaken with federal law enforcement. To underscore the risks of fentanyl after last week‚Äôs day care death, the city on Wednesday held a news conference to announce a large guns and drugs bust in Queens.\n",
    "\n",
    "Ms. Brennan said that last year, her office seized about 1,000 pounds of fentanyl off the street and about one million pills. Police officials said an additional 150 officers have been added to narcotics squads recently, with plans for more. Each borough has two teams of officers assigned to investigate 911 and 311 calls about drug-related complaints. Additional units conduct ‚Äúbuy and bust‚Äù operations, where undercover officers make multiple drug buys from the same dealer in order to catch the more prolific street-level dealers.\n",
    "\n",
    "‚ÄúOur goal is that citizens shouldn‚Äôt have to walk past a drug dealer to get into their building,‚Äù Chief Kenny said.\n",
    "\n",
    "Yet in some pockets, like Kingsbridge, several residents said it feels so unsafe that they have stopped leaving the house after 6 p.m. ‚ÄúYou‚Äôll come down the stairs with the kids in the morning and there‚Äôs someone sitting there, just shooting up,‚Äù said Chris Castellanos, 35, a father of four children.\n",
    "\n",
    "Karla Cabrera Carrera, the district manager of Community Board 7, which includes Kingsbridge, said that society has to think about the rights of residents to feel secure, too.\n",
    "\n",
    "‚ÄúWe are really facing a really bad issue,‚Äù she said. ‚ÄúI love the Bronx, I don‚Äôt want to have to move, but at this point, we are all desperate to find a solution to all of it.‚Äù\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8baa6a",
   "metadata": {},
   "source": [
    "I put together a template that we can use to send the article to GPT. The `{text}` part gets filled in with whatever we want - in this case it's the article, but we'll expand on this in other directions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a341d4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize the article below:\n",
      "\n",
      "This fills in the blank\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Summarize the article below:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=\"This fills in the blank\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd23f9f",
   "metadata": {},
   "source": [
    "Now let's do all of the steps:\n",
    "\n",
    "1. Connect to GPT\n",
    "2. Create our prompt\n",
    "3. Send it over\n",
    "\n",
    "Note that if you get an error, make sure you're run the cell above that creates the article! You need to click it and shift+enter, or press the \"Run\" button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bdb51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# You'll need your own OpenAI GPT API key! This one was mine,\n",
    "# but I've deactivated it so I can publish this.\n",
    "API_KEY = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "881f4ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City's open-air drug markets, in areas such as the Bronx's Kingsbridge Road underpass, are becoming more of a problem, with police rarely intervening and overdoses at a record high. The city's special narcotics prosecutor‚Äôs office has reported that 3,200 deaths occurred in 2022 due to overdoses. The dilemma for the city is how to address the epidemic without resorting to aggressive crackdowns that have previously led to civil rights abuses and have not effectively curbed drug use. The situation is particularly concerning with the rise of fentanyl, a powerful synthetic opioid, which is becoming increasingly deadly. Over 1,500 children died from fentanyl overdoses in 2021, with over 100 of them being under the age of four. The city and state have been moving away from aggressive law enforcement of street drugs, instead viewing drug use as a public health crisis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Summarize the article below:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=article)\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013318d",
   "metadata": {},
   "source": [
    "This gets us an answer, but *can we write a better prompt?*\n",
    "\n",
    "Think about asking GPT to use a specific tone, or cheat a little by telling it to copy a publication. You can also set a length, reading level or target audience!\n",
    "\n",
    "I also recommend asking your tools for suggestions ‚Äì you can try asking ChatGPT \"how would you describe the writing style of the New York Times? Be detailed.\" and use that as a jumping-off point.\n",
    "\n",
    "> Don't ever feel like your prompt is too long! Check the [EditorBot prompt](https://jamditis.notion.site/Superprompt-EditorBot-for-feedback-on-your-writing-0268051a8f384762a2686b1d43ad390b) - it's approximately ten million words long! You can always refine it later if you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab89a6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open-air drug markets persist in New York City, even as the city grapples with a record high number of overdose deaths. The city's approach to drug use has shifted away from aggressive law enforcement towards treating it as a public health crisis, leading to a rise in visible drug use in areas ranging from low-income neighborhoods to tourist hubs. Critics argue this approach has led to an increase in violence and has made it harder to prosecute those higher up the drug chain. Meanwhile, the rise of fentanyl, a highly potent drug, has increased the stakes, with over 1,500 children dying from fatal overdoses in 2021. The city has responded by setting up supervised drug consumption sites, but these are often in a legal grey area and lack sufficient funding.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Summarize the article below:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=article)\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479d50c",
   "metadata": {},
   "source": [
    "## Document summaries (research)\n",
    "\n",
    "### Text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "246a90b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll add this later!\n",
    "# You don't normally have text files, do you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c30d89d",
   "metadata": {},
   "source": [
    "### PDF\n",
    "\n",
    "PDFs are common sources for longer documents - reports, academic papers, etc.\n",
    "\n",
    "I like using [pdfminer.six](https://pdfminersix.readthedocs.io/en/latest/) to extract text from PDFs, it's super time. We'll first pull the text out, then try to send it to GPT for a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baaf7460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLIS\n",
      "\n",
      "Journalism at LSE\n",
      "\n",
      "Generating Change\n",
      "A global survey of what news \n",
      "organisations are doing with AI \n",
      "\n",
      "Charlie Beckett and Mira Yaseen\n",
      "\n",
      "\f",
      "Preface\n",
      "\n",
      "Our news media world has been turned upside down again. As always, serious technological \n",
      "change produces both dystopian and utopian hype. Much of this has been generated on social \n",
      "media by corporate PR and politicians. News coverage and expert commentary has also \n",
      "veered from excited coverage of positive breakthroughs in fields such as medicine to much \n",
      "more frightening visions of negative forces unleashed: Generative AI (genAI) is producing a \n",
      "tidal wave of automated, undetectable disinformation; it will amplify discrimination, extreme \n",
      "speech and inequalities.¬†\n",
      "\n",
      "And its impact on journalism? Again, much of the coverage has focused on the unreliability of \n",
      "many genAI tools and the controversy over its rapacious appetite for other people‚Äôs data to train \n",
      "its algorithms. As the initial storm of hype turns into more practical considerati\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "pdf_text = extract_text(\"data-files/ai-report.pdf\")\n",
    "print(pdf_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01671e8",
   "metadata": {},
   "source": [
    "Now let's use a simple summarization prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1abfc0c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 8192 tokens. However, your messages resulted in 33095 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_m/b8tjbm6n4zs1q2mvjvg25x1m0000gn/T/ipykernel_39028/755854320.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpdf_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text, stop, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0m_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     ) -> BaseMessage:\n\u001b[0;32m--> 194\u001b[0;31m         generation = self.generate(\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         ).generations[0][0]\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mllm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_llm_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         )\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             results = [\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             results = [\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m             )\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_llm_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mis_explicit_retry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTryAgain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36m_completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mretry_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             )\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 8192 tokens. However, your messages resulted in 33095 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Summarize the paper below:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=pdf_text)\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a8a632",
   "metadata": {},
   "source": [
    "**We get an error!** This is because our text is longer than GPT's **token limit.**\n",
    "\n",
    "To make this summarization work, we have to **split our document into pieces!**\n",
    "\n",
    "> Instead of the AI report, I'm also going to shift to using a slightly shorter academic paper! The AI report gets broken into about 90 pieces which takes a while to process. The science paper is only a *little* long, so it's just 21 segments.\n",
    ">\n",
    "> If you'd like to try the AI report (and wait a while in the process), feel free to change the filename.\n",
    "\n",
    "We'll start by reading in our document, and using `load_and_split` to divide it up into separate pages. Later on we'll show an example of a more \"intelligent\" splitting that understands headers and sections, but this one is a simple example for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cd52b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('data-files/science-paper.pdf')\n",
    "docs = loader.load_and_split()\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba5a1a",
   "metadata": {},
   "source": [
    "Then we'll connect to GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83d3bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# You'll need your own OpenAI GPT API key! This one was mine,\n",
    "# but I've deactivated it so I can publish this.\n",
    "API_KEY = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e912cb",
   "metadata": {},
   "source": [
    "Finally, we'll create a prompt to summarize the pieces. It's a lot of code, but I promise you'll (almost???) always use the same one every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b7313c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "prompt_template = \"\"\"Summarize the following document.\n",
    "\n",
    "\n",
    "TEXT: {text}\n",
    "\n",
    "\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "chain = load_summarize_chain(llm,\n",
    "                             chain_type=\"map_reduce\",\n",
    "                             return_intermediate_steps=True,\n",
    "                             map_prompt=PROMPT,\n",
    "                             combine_prompt=PROMPT)\n",
    "\n",
    "result = chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb0fc411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document is a review of the nutrient composition and value of milk and plant-based milk alternatives. It compares the protein, fat, and calcium content of various plant-based milks to cow's milk. The review finds that plant-based milk alternatives often have lower nutritional value, particularly in terms of protein content. It also discusses other factors such as vitamin and mineral content and absorption. The document highlights the importance of understanding the implications of using plant-based milk alternatives as nutritional replacements. It mentions public health concerns related to the consumption of milk and provides references to studies on nutrition and health. Overall, the document concludes that plant-based milk alternatives are generally nutritionally inferior to cow's milk and should not be considered as complete nutritional alternatives.\n"
     ]
    }
   ],
   "source": [
    "print(result['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d66d6",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "While we *could* use something like DeepL or Google Translate, why not just use the LLM for *absolutely everything?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da04125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A K√ìR√ì √âS A KIS MAD√ÅR.\n",
      "\n",
      "Egyszer volt, hol nem volt, volt a vil√°gon egy kis mad√°r. Ez a kis mad√°r\n",
      "egyszer nagyon megunta mag√°t, r√°sz√°llt egy k√≥r√≥ra:\n",
      "\n",
      "‚Äì Kis k√≥r√≥ ringass engemet!\n",
      "\n",
      "‚Äì Nem ringatom biz √©n senki kis madar√°t!\n",
      "\n",
      "A kis mad√°r megharagudott, elrep√ºlt onnan. A mint ment mendeg√©lt, tal√°lt\n",
      "egy kecsk√©t:\n",
      "\n",
      "‚Äì Kecske! r√°gd el a k√≥r√≥t!\n",
      "\n",
      "Kecske nem ment k√≥r√≥ r√°gni, a k√≥r√≥ m√©g se‚Äô ringatta a kis madarat.\n",
      "Megint ment mendeg√©lt a kis mad√°r, tal√°lt egy farkast:\n",
      "\n",
      "‚Äì Farkas! edd meg a kecsk√©t!\n",
      "\n",
      "Farkas nem ment kecske enni, kecske nem ment k√≥r√≥ r√°gni, k√≥r√≥ m√©g se‚Äô\n",
      "ringatta a kis madarat.\n",
      "\n",
      "Megint ment mendeg√©lt a kis mad√°r, tal√°lt egy falut:\n",
      "\n",
      "‚Äì Falu! kergesd el a farkast!\n",
      "\n",
      "Falu nem ment farkas kergetni, farkas nem ment kecske enni, kecske nem\n",
      "ment k√≥r√≥ r√°gni, a k√≥r√≥ m√©g se‚Äô ringatta a kis madarat;\n",
      "\n",
      "Megint ment mendeg√©lt a kis mad√°r, tal√°lt egy t√ºzet:\n",
      "\n",
      "‚Äì T≈±z! √©gesd meg a falut.\n",
      "\n",
      "T≈±z nem ment falu √©getni, falu nem ment farkas kergetni, farkas nem ment\n",
      "kecske enni, kecske nem ment k√≥r√≥ r√°gni, a k√≥r√≥ m√©g se‚Äô ringatta a kis\n",
      "madarat.\n",
      "\n",
      "Megint ment mendeg√©lt a kis mad√°r, tal√°lt egy vizet:\n",
      "\n",
      "‚Äì Viz! oltsd el a t√ºzet.\n",
      "\n",
      "Viz nem ment t√ºzet oltani, t≈±z nem ment falu √©getni, falu nem ment\n",
      "farkas kergetni, farkas nem ment kecske enni, kecske nem ment k√≥r√≥\n",
      "r√°gni, a k√≥r√≥ m√©g se‚Äô ringatta a kis madarat.\n",
      "\n",
      "Megint ment mendeg√©lt a kis mad√°r, tal√°lt egy bik√°t:\n",
      "\n",
      "‚Äì Bika! idd fel a vizet!\n",
      "\n",
      "Bika nem ment vizet inni, viz nem ment t√ºzet oltani, t≈±z nem ment falu\n",
      "√©getni, falu nem ment farkas kergetni, farkas nem ment kecske enni,\n",
      "kecske nem ment k√≥r√≥ r√°gni, a k√≥r√≥ m√©g se‚Äô ringatta a kis madarat.\n",
      "\n",
      "Megint ment mendeg√©lt a kis mad√°r, tal√°lt egy furk√≥t.\n",
      "\n",
      "‚Äì Furk√≥ √ºsd agyon a bik√°t.\n",
      "\n",
      "Furk√≥ nem ment bika √ºtni, bika nem ment vizet inni, viz nem ment t√ºzet\n",
      "oltani, t≈±z nem ment falu √©getni, falu nem ment farkas kergetni, farkas\n",
      "nem ment kecske enni, kecske nem ment k√≥r√≥ r√°gni, a k√≥r√≥ m√©g se‚Äô\n",
      "ringatta a kis madarat.\n",
      "\n",
      "Megint ment mendeg√©lt a kis mad√°r, tal√°lt egy f√©rget.\n",
      "\n",
      "‚Äì F√©reg f√∫rd ki a furk√≥t.\n",
      "\n",
      "F√©reg nem ment furk√≥t f\n"
     ]
    }
   ],
   "source": [
    "folktale = open(\"data-files/folktale-short.txt\").read()\n",
    "print(folktale[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe578b",
   "metadata": {},
   "source": [
    "Like always, we'll start by connecting to ChatGPT, build a prompt, then send it over to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cdc2b54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONCE UPON A TIME THERE WAS A DISEASE AND A LITTLE BIRD.\n",
      "\n",
      "Once upon a time, in a land far away, there was a little bird. This little bird got very bored and landed on a branch:\n",
      "\n",
      "- Little branch, rock me to sleep!\n",
      "\n",
      "- I don't rock any little birds!\n",
      "\n",
      "The little bird got angry and flew away. As it wandered, it found a goat:\n",
      "\n",
      "- Goat, chew on the branch!\n",
      "\n",
      "The goat didn't chew on the branch, and the branch still didn't rock the little bird. The little bird continued on its way and found a wolf:\n",
      "\n",
      "- Wolf, eat the goat!\n",
      "\n",
      "The wolf didn't eat the goat, the goat didn't chew on the branch, and the branch still didn't rock the little bird.\n",
      "\n",
      "The little bird continued on its way and found a village:\n",
      "\n",
      "- Village, chase away the wolf!\n",
      "\n",
      "The village didn't chase away the wolf, the wolf didn't eat the goat, the goat didn't chew on the branch, and the branch still didn't rock the little bird.\n",
      "\n",
      "The little bird continued on its way and found a fire:\n",
      "\n",
      "- Fire, burn down the village.\n",
      "\n",
      "The fire didn't burn down the village, the village didn't chase away the wolf, the wolf didn't eat the goat, the goat didn't chew on the branch, and the branch still didn't rock the little bird.\n",
      "\n",
      "The little bird continued on its way and found water:\n",
      "\n",
      "- Water, put out the fire.\n",
      "\n",
      "The water didn't put out the fire, the fire didn't burn down the village, the village didn't chase away the wolf, the wolf didn't eat the goat, the goat didn't chew on the branch, and the branch still didn't rock the little bird.\n",
      "\n",
      "The little bird continued on its way and found a bull:\n",
      "\n",
      "- Bull, drink the water!\n",
      "\n",
      "The bull didn't drink the water, the water didn't put out the fire, the fire didn't burn down the village, the village didn't chase away the wolf, the wolf didn't eat the goat, the goat didn't chew on the branch, and the branch still didn't rock the little bird.\n",
      "\n",
      "The little bird continued on its way and found a pitchfork.\n",
      "\n",
      "- Pitchfork, kill the bull.\n",
      "\n",
      "The pitchfork didn't kill the bull, the bull didn't drink the water, the water didn't put out the fire, the fire didn't burn down the village, the village didn't chase away the wolf, the wolf didn't eat the goat, the goat didn't chew on the branch, and the branch still didn't rock the little bird.\n",
      "\n",
      "The little bird continued on its way and found a worm.\n",
      "\n",
      "- Worm, dig into the pitchfork.\n",
      "\n",
      "The worm didn't dig into the pitchfork, the pitchfork didn't kill the bull, the bull didn't drink the water, the water didn't put out the fire, the fire didn't burn down the village, the village didn't chase away the wolf, the wolf didn't eat the goat, the goat didn't chew on the branch, and the branch still didn't rock the little bird.\n",
      "\n",
      "The little bird continued on its way and found a rooster.\n",
      "\n",
      "- Rooster, pick up the worm.\n",
      "\n",
      "The rooster ran, picked up the worm, the worm ran, gnawed on the pitchfork, the pitchfork ran, hit the bull, the bull ran, drank the water, the water ran, put out the fire, the fire ran, burned the village, the village ran, chased the wolf, the wolf ran, ate the goat, the goat ran, chewed on the branch, and the branch finally rocked the little bird.\n",
      "\n",
      "If it still hadn't rocked the little bird, my story would have continued.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# You'll need your own OpenAI GPT API key! This one was mine,\n",
    "# but I've deactivated it so I can publish this.\n",
    "API_KEY = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "template = \"\"\"\n",
    "Translate the text below into English:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=folktale)\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeadeb3",
   "metadata": {},
   "source": [
    "What happens if we try with `gpt-4` instead of `gpt-3.5-turbo`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca5d88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# You'll need your own OpenAI GPT API key! This one was mine,\n",
    "# but I've deactivated it so I can publish this.\n",
    "API_KEY = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-4\")\n",
    "\n",
    "template = \"\"\"\n",
    "Translate the text below into English:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(text=folktale)\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54ad88",
   "metadata": {},
   "source": [
    "## Transcription (speech to text)\n",
    "\n",
    "[Whisper](https://github.com/openai/whisper) is a transcription engine. You can use the code below to read from an mp3, or you can [try the interactive version](https://huggingface.co/spaces/openai/whisper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d443a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soma/.pyenv/versions/3.10.3/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"sample-audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "edd5fe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Okay, I was wondering if you could tell me a little bit about the program. What exactly goes on? Okay, well basically it's an intensive program designed to last four weeks, each session is four weeks long, although we do have two sessions in 1996 that will be two weeks long. But our general four weeks session involves seven hours of contact each day of Spanish. It involves starting at nine o'clock in the morning with three hours of grammar instruction. And then it's followed immediately by an hour of group conversation with the same instructor, same class, but we have extensive gardens here at the Institute and so students will usually go out to a garden setting because it's a little more comfortable. And then after a break for lunch, students return and we have a complete flip of instruction in that instead of textbook and clinical type instruction, we have hands on and we offer workshops in Mejibak's drop leaving, regional cooking of Wahaka at Donpas-Nal pottery. And if we have larg\n"
     ]
    }
   ],
   "source": [
    "print(result[\"text\"][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af19f6",
   "metadata": {},
   "source": [
    "In the example above, we use the `base` model. You can see [the different model versions here](https://github.com/openai/whisper#available-models-and-languages), which vary in their accuracy and knowledge of non-English languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f44fb80",
   "metadata": {},
   "source": [
    "## Reading text out loud (text to speech)\n",
    "\n",
    "[Text to speech models on HuggingFace](https://huggingface.co/models?pipeline_tag=text-to-speech&sort=trending). They... are mostly not that good. Usually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0bf33",
   "metadata": {},
   "source": [
    "### Voice cloning\n",
    "\n",
    "I'm just going to send you to [ElevenLabs](https://elevenlabs.io/). I showed you an example in class, but I don't have an interactive one here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f965974",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "\n",
    "### Zero-shot classification\n",
    "\n",
    "Because large language models are remarkably well-read, they're very good at categorizing content for you. If your categories are nuanced and specific it's a little more trouble, but if you're categorizing content across *broad categories* it should do a great job.\n",
    "\n",
    "Here's a basic example of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83edcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Categorize the following text as being about ENVIRONMENT, GUN CONTROL,\n",
    "or IMMIGRATION. Respond with only the category.\n",
    "\n",
    "Text: A Bill to Regulate the Sulfur Emissions of Coal-Fired Energy\n",
    "Plants in the State of New York.\n",
    "\"\"\"\n",
    "\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba5c8e0",
   "metadata": {},
   "source": [
    "Instead of writing the big long `\"Categorize the following text...\"` prompt for *every single bill*, we can also use Python's `.format`. It allows us to write the prompt once, then fill in the blanks for the part that changes each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7bff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Categorize the following text as being about ENVIRONMENT, GUN CONTROL,\n",
    "or IMMIGRATION. Respond with only the category.\n",
    "\n",
    "Text: {bill_text}\n",
    "\"\"\"\n",
    "\n",
    "print(template.format(bill_text=\"This fills in the spot in the template\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c6760",
   "metadata": {},
   "source": [
    "This is super convenient if we want to categorize many things! For example, you might use a loop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4924dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Categorize the following text as being about ENVIRONMENT, GUN CONTROL,\n",
    "or IMMIGRATION. Respond with only the category.\n",
    "\n",
    "Text: {bill_text}\n",
    "\"\"\"\n",
    "\n",
    "bills = [\n",
    "    \"A Bill to Allow Additional Refugees In Upstate New York\",\n",
    "    \"A Bill to Close Down Coal-fired Power Plants\",\n",
    "    \"A Bill to Banning Assault Rifles at Public Events\"\n",
    "]\n",
    "\n",
    "for bill in bills:\n",
    "    prompt = template.format(bill_text=bill)\n",
    "    response = llm.predict(prompt)\n",
    "    print(bill, \"is\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ababf5",
   "metadata": {},
   "source": [
    "...or if you have a pandas DataFrame, you can use `.apply` and build a new column for your category!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d43740c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Bill to Allow Additional Refugees In Upstate New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Bill to Close Down Coal-fired Power Plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Bill to Banning Assault Rifles at Public Events</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title\n",
       "0  A Bill to Allow Additional Refugees In Upstate New York\n",
       "1             A Bill to Close Down Coal-fired Power Plants\n",
       "2        A Bill to Banning Assault Rifles at Public Events"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 500)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'title': [\n",
    "        \"A Bill to Allow Additional Refugees In Upstate New York\",\n",
    "        \"A Bill to Close Down Coal-fired Power Plants\",\n",
    "        \"A Bill to Banning Assault Rifles at Public Events\"\n",
    "    ]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Categorize the following text as being about ENVIRONMENT, GUN CONTROL,\n",
    "or IMMIGRATION. Respond with only the category.\n",
    "\n",
    "Text: {bill_text}\n",
    "\"\"\"\n",
    "\n",
    "def make_prediction(row):\n",
    "    text = row['title']\n",
    "    prompt = template.format(bill_text=text)\n",
    "    response = llm.predict(prompt)\n",
    "    return response\n",
    "\n",
    "# Send each row to make_prediction and store the category in a new column\n",
    "df['predicted_category'] = df.apply(make_prediction, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e004e038",
   "metadata": {},
   "source": [
    "It's like magic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd189d",
   "metadata": {},
   "source": [
    "### GPT in Google Sheets\n",
    "\n",
    "You can also do this with GPT [in Google Sheets](https://www.makeuseof.com/how-use-chatgpt-google-sheets/) instead of relying on code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8cfb4",
   "metadata": {},
   "source": [
    "### Few-shot classification\n",
    "\n",
    "Sometimes your classifier might not do a great job. It might be a topic the LLM doesn't know much about, you might be asking for nuance it doesn't have out of the box, or a million and one other things might be going wrong. In those cases, it's useful to try **few-shot classification**.\n",
    "\n",
    "In the same way that zero-shot classification takes zero examples going in, few-shot classification takes... a few examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Categorize the following text as being about ENVIRONMENT, GUN CONTROL,\n",
    "or IMMIGRATION. Respond with only the category.\n",
    "\n",
    "Text: Something about immigration\n",
    "IMMIGRATION\n",
    "\n",
    "Text: Something about gun control\n",
    "GUN CONTROL\n",
    "\n",
    "Text: {bill_text}\n",
    "\"\"\"\n",
    "\n",
    "print(template.format(bill_text=\"This fills in the spot in the template\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be6b44",
   "metadata": {},
   "source": [
    "### Custom classifiers\n",
    "\n",
    "You can also use [Hugging Face AutoTrain](https://ui.autotrain.huggingface.co/) to train your own classifiers. Instead of trusting that the model has enough information about the world to make a decision, you give it exactly what it needs to know.\n",
    "\n",
    "They aren't necessarily worse or better: they're just more work on your end because you have to manually label each category to show it what you mean. Instead of \"few shot\" it's \"a whole lot of shots\" - probably hundreds!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a8793",
   "metadata": {},
   "source": [
    "## Format shifting\n",
    "\n",
    "A lot of the power of these models involves format shifting, changing from one format to another. Audio, text, images, video.\n",
    "\n",
    "* **Video to image:** then analyze the images\n",
    "* **Audio to text:** transcription\n",
    "* **Text to image:** I think this one is immoral. Art is resistant to errors, so it's much easier to just rip off someone's style. It's also trained on peoples' work in a way that's far more obviously inappropriate than text models.\n",
    "* **Image to text:** accessibility and research\n",
    "\n",
    "If you have a lot of content in one category, it's worth thinking about what you can do to convert it into another category and re-use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb1675",
   "metadata": {},
   "source": [
    "## Image models\n",
    "\n",
    "The three major things you can do with images is:\n",
    "\n",
    "1. Categorize your images\n",
    "2. Detect objects in the images\n",
    "3. Separate your image into pieces (pixel counting)\n",
    "\n",
    "If you use [HuggingFace AutoTrain](https://ui.autotrain.huggingface.co/), you can easily make your own models! I made one [to classify illegal amber mines](https://huggingface.co/wendys-llc/amber-mines) based on [Texty's work](https://texty.org.ua/d/2018/amber_eng/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3503edb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4404f7a46af444078ca9ac0b71209edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/763 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4143a5dbf149448a6cfc2da7393442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/343M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454ab3966b194bfc91ff8e3b820e54cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)rocessor_config.json:   0%|          | 0.00/325 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"image-classification\", model=\"wendys-llc/amber-mines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e9b99",
   "metadata": {},
   "source": [
    "What does the model think about this image?\n",
    "\n",
    "![](amber-sample-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be435250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9965369701385498, 'label': 'negative'},\n",
       " {'score': 0.003463044995442033, 'label': 'positive'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"amber-sample-1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66537a65",
   "metadata": {},
   "source": [
    "How about this one?\n",
    "\n",
    "![](amber-sample-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ec74223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9864670634269714, 'label': 'positive'},\n",
       " {'score': 0.013532912358641624, 'label': 'negative'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"amber-sample-2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eab679",
   "metadata": {},
   "source": [
    "### Object detection\n",
    "\n",
    "[Here is an example of object detection](https://huggingface.co/spaces/wendys-llc/OWL-ViT)\n",
    "\n",
    "You can combine this with a large language model to ask questions of images. \"Are there cats in this image?\" It's like a more flexible classifier ‚Äì but with limitations about what the model knows about.\n",
    "\n",
    "### Semantic segmentation\n",
    "\n",
    "[Here is an example of semantic segmentation](https://huggingface.co/spaces/thiagohersan/maskformer-satellite-trees-gradio)\n",
    "\n",
    "How much of this image is pavement? Or grass? Or trees? Or cars?\n",
    "\n",
    "Not too useful with normal imagery, but very useful for satellite or aerial imagery.\n",
    "\n",
    "### Panoptic segmentation\n",
    "\n",
    "[Here is an example of panoptic segmentation](https://huggingface.co/spaces/wendys-llc/panoptic-segment-anything)\n",
    "\n",
    "Panoptic segmentation does both object detection *and* semantic segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e222778f",
   "metadata": {},
   "source": [
    "## Semantic search\n",
    "\n",
    "A combination of semantic search and keyword matching usually outperforms semantic search by itself.\n",
    "\n",
    "Transcribing all of your interviews and then doing searches across them is a beautiful thing.\n",
    "\n",
    "Give [Semantra](https://github.com/freedmand/semantra) a try to run it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daca0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3be44deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0676569   0.06349581  0.0487131   0.07930496  0.03744796  0.00265277\n",
      "  0.03937485 -0.00709837  0.0593615   0.03153696  0.06009803 -0.05290522\n",
      "  0.04060676 -0.02593078  0.02984274  0.00112689  0.07351495 -0.05038185\n",
      " -0.12238666  0.02370274  0.02972649  0.04247681  0.0256338   0.00199517\n",
      " -0.05691912 -0.02715985 -0.03290359  0.06602488  0.11900704 -0.04587924\n",
      " -0.07262138 -0.03258408  0.05234135  0.04505523  0.00825302  0.03670237\n",
      " -0.01394151  0.06539196 -0.02642729  0.00020634 -0.01366437 -0.03628108\n",
      " -0.0195043  -0.02897387  0.03942709 -0.08840913  0.00262434  0.01367143\n",
      "  0.04830637 -0.03115652]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "331f223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentences = [\n",
    "    \"Molly ate a fish\",\n",
    "    \"Jen consumed a carp\",\n",
    "    \"I would like to sell you a house\",\n",
    "    \"–Ø –ø—ã—Ç–∞—é—Å—å –∫—É–ø–∏—Ç—å –¥–∞—á—É\", # I'm trying to buy a summer home\n",
    "    \"J'aimerais vous louer un grand appartement\", # I would like to rent a large apartment to you\n",
    "    \"This is a wonderful investment opportunity\",\n",
    "    \"–≠—Ç–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π\", # investment opportunity\n",
    "    \"C'est une merveilleuse opportunit√© d'investissement\", # investment opportunity\n",
    "    \"„Åì„Çå„ÅØÁ¥†Êô¥„Çâ„Åó„ÅÑÊäïË≥áÊ©ü‰ºö„Åß„Åô\", # investment opportunity\n",
    "    \"ÈáéÁêÉ„ÅØ„ÅÇ„Å™„Åü„ÅåÊÄù„ÅÜ„Çà„Çä„ÇÇÈù¢ÁôΩ„ÅÑ„Åì„Å®„Åå„ÅÇ„Çä„Åæ„Åô\", # baseball can be more interesting than you think\n",
    "    \"Baseball can be interesting than you'd think\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6d9da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7fa8bd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ed13a_row0_col0, #T_ed13a_row1_col1, #T_ed13a_row2_col2, #T_ed13a_row3_col3, #T_ed13a_row4_col4, #T_ed13a_row5_col5, #T_ed13a_row6_col6, #T_ed13a_row7_col7, #T_ed13a_row8_col8, #T_ed13a_row9_col9, #T_ed13a_row10_col10 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed13a_row0_col1, #T_ed13a_row1_col0 {\n",
       "  background-color: #4e9ac6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed13a_row0_col2, #T_ed13a_row0_col8, #T_ed13a_row2_col0, #T_ed13a_row2_col9, #T_ed13a_row8_col0, #T_ed13a_row9_col2 {\n",
       "  background-color: #ebe6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row0_col3, #T_ed13a_row3_col0 {\n",
       "  background-color: #dddbec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row0_col4, #T_ed13a_row0_col10, #T_ed13a_row4_col0, #T_ed13a_row5_col8, #T_ed13a_row8_col5, #T_ed13a_row10_col0 {\n",
       "  background-color: #ece7f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row0_col5, #T_ed13a_row5_col0 {\n",
       "  background-color: #f8f1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row0_col6, #T_ed13a_row1_col3, #T_ed13a_row3_col1, #T_ed13a_row6_col0 {\n",
       "  background-color: #e9e5f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row0_col7, #T_ed13a_row7_col0 {\n",
       "  background-color: #f7f0f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row0_col9, #T_ed13a_row1_col10, #T_ed13a_row2_col6, #T_ed13a_row6_col2, #T_ed13a_row9_col0, #T_ed13a_row10_col1 {\n",
       "  background-color: #ede7f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row1_col2, #T_ed13a_row2_col1 {\n",
       "  background-color: #e7e3f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row1_col4, #T_ed13a_row4_col1 {\n",
       "  background-color: #f1ebf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row1_col5, #T_ed13a_row2_col7, #T_ed13a_row5_col1, #T_ed13a_row5_col9, #T_ed13a_row7_col2, #T_ed13a_row9_col5 {\n",
       "  background-color: #f0eaf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row1_col6, #T_ed13a_row6_col1 {\n",
       "  background-color: #faf2f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row1_col7, #T_ed13a_row4_col10, #T_ed13a_row7_col1, #T_ed13a_row10_col4 {\n",
       "  background-color: #f1ebf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row1_col8, #T_ed13a_row3_col7, #T_ed13a_row7_col3, #T_ed13a_row8_col1 {\n",
       "  background-color: #dedcec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row1_col9, #T_ed13a_row9_col1 {\n",
       "  background-color: #d6d6e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row2_col3, #T_ed13a_row3_col2 {\n",
       "  background-color: #d2d2e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row2_col4, #T_ed13a_row4_col2 {\n",
       "  background-color: #e0dded;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row2_col5, #T_ed13a_row5_col2 {\n",
       "  background-color: #88b1d4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row2_col8, #T_ed13a_row8_col2 {\n",
       "  background-color: #eee8f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row2_col10, #T_ed13a_row7_col10, #T_ed13a_row10_col2, #T_ed13a_row10_col7 {\n",
       "  background-color: #eee9f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row3_col4, #T_ed13a_row4_col3 {\n",
       "  background-color: #d1d2e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row3_col5, #T_ed13a_row5_col3 {\n",
       "  background-color: #e3e0ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row3_col6, #T_ed13a_row6_col3 {\n",
       "  background-color: #69a5cc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed13a_row3_col8, #T_ed13a_row8_col3 {\n",
       "  background-color: #a1bbda;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row3_col9, #T_ed13a_row9_col3 {\n",
       "  background-color: #9cb9d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row3_col10, #T_ed13a_row10_col3 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row4_col5, #T_ed13a_row5_col4 {\n",
       "  background-color: #eae6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row4_col6, #T_ed13a_row6_col4 {\n",
       "  background-color: #8fb4d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row4_col7, #T_ed13a_row7_col4 {\n",
       "  background-color: #3d93c2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed13a_row4_col8, #T_ed13a_row8_col4 {\n",
       "  background-color: #cdd0e5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row4_col9, #T_ed13a_row9_col4 {\n",
       "  background-color: #dad9ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row5_col6, #T_ed13a_row6_col5 {\n",
       "  background-color: #f3edf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row5_col7, #T_ed13a_row7_col5 {\n",
       "  background-color: #c1cae2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row5_col10, #T_ed13a_row10_col5 {\n",
       "  background-color: #d9d8ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row6_col7, #T_ed13a_row7_col6 {\n",
       "  background-color: #acc0dd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row6_col8, #T_ed13a_row8_col6 {\n",
       "  background-color: #b0c2de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row6_col9, #T_ed13a_row9_col6 {\n",
       "  background-color: #abbfdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row6_col10, #T_ed13a_row10_col6 {\n",
       "  background-color: #f4eef6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row7_col8, #T_ed13a_row8_col7 {\n",
       "  background-color: #a8bedc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row7_col9, #T_ed13a_row9_col7 {\n",
       "  background-color: #c8cde4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed13a_row8_col9, #T_ed13a_row9_col8 {\n",
       "  background-color: #3790c0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed13a_row8_col10, #T_ed13a_row9_col10, #T_ed13a_row10_col8, #T_ed13a_row10_col9 {\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ed13a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ed13a_level0_col0\" class=\"col_heading level0 col0\" >Molly ate a fish</th>\n",
       "      <th id=\"T_ed13a_level0_col1\" class=\"col_heading level0 col1\" >Jen consumed a carp</th>\n",
       "      <th id=\"T_ed13a_level0_col2\" class=\"col_heading level0 col2\" >I would like to sell you a house</th>\n",
       "      <th id=\"T_ed13a_level0_col3\" class=\"col_heading level0 col3\" >–Ø –ø—ã—Ç–∞—é—Å—å –∫—É–ø–∏—Ç—å –¥–∞—á—É</th>\n",
       "      <th id=\"T_ed13a_level0_col4\" class=\"col_heading level0 col4\" >J'aimerais vous louer un grand appartement</th>\n",
       "      <th id=\"T_ed13a_level0_col5\" class=\"col_heading level0 col5\" >This is a wonderful investment opportunity</th>\n",
       "      <th id=\"T_ed13a_level0_col6\" class=\"col_heading level0 col6\" >–≠—Ç–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π</th>\n",
       "      <th id=\"T_ed13a_level0_col7\" class=\"col_heading level0 col7\" >C'est une merveilleuse opportunit√© d'investissement</th>\n",
       "      <th id=\"T_ed13a_level0_col8\" class=\"col_heading level0 col8\" >„Åì„Çå„ÅØÁ¥†Êô¥„Çâ„Åó„ÅÑÊäïË≥áÊ©ü‰ºö„Åß„Åô</th>\n",
       "      <th id=\"T_ed13a_level0_col9\" class=\"col_heading level0 col9\" >ÈáéÁêÉ„ÅØ„ÅÇ„Å™„Åü„ÅåÊÄù„ÅÜ„Çà„Çä„ÇÇÈù¢ÁôΩ„ÅÑ„Åì„Å®„Åå„ÅÇ„Çä„Åæ„Åô</th>\n",
       "      <th id=\"T_ed13a_level0_col10\" class=\"col_heading level0 col10\" >Baseball can be interesting than you'd think</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ed13a_level0_row0\" class=\"row_heading level0 row0\" >Molly ate a fish</th>\n",
       "      <td id=\"T_ed13a_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_ed13a_row0_col1\" class=\"data row0 col1\" >0.526053</td>\n",
       "      <td id=\"T_ed13a_row0_col2\" class=\"data row0 col2\" >0.025476</td>\n",
       "      <td id=\"T_ed13a_row0_col3\" class=\"data row0 col3\" >0.098335</td>\n",
       "      <td id=\"T_ed13a_row0_col4\" class=\"data row0 col4\" >0.020435</td>\n",
       "      <td id=\"T_ed13a_row0_col5\" class=\"data row0 col5\" >-0.065293</td>\n",
       "      <td id=\"T_ed13a_row0_col6\" class=\"data row0 col6\" >0.035801</td>\n",
       "      <td id=\"T_ed13a_row0_col7\" class=\"data row0 col7\" >-0.062506</td>\n",
       "      <td id=\"T_ed13a_row0_col8\" class=\"data row0 col8\" >0.027358</td>\n",
       "      <td id=\"T_ed13a_row0_col9\" class=\"data row0 col9\" >0.017622</td>\n",
       "      <td id=\"T_ed13a_row0_col10\" class=\"data row0 col10\" >0.023445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed13a_level0_row1\" class=\"row_heading level0 row1\" >Jen consumed a carp</th>\n",
       "      <td id=\"T_ed13a_row1_col0\" class=\"data row1 col0\" >0.526053</td>\n",
       "      <td id=\"T_ed13a_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_ed13a_row1_col2\" class=\"data row1 col2\" >0.044178</td>\n",
       "      <td id=\"T_ed13a_row1_col3\" class=\"data row1 col3\" >0.035044</td>\n",
       "      <td id=\"T_ed13a_row1_col4\" class=\"data row1 col4\" >-0.018194</td>\n",
       "      <td id=\"T_ed13a_row1_col5\" class=\"data row1 col5\" >-0.004438</td>\n",
       "      <td id=\"T_ed13a_row1_col6\" class=\"data row1 col6\" >-0.078566</td>\n",
       "      <td id=\"T_ed13a_row1_col7\" class=\"data row1 col7\" >-0.011418</td>\n",
       "      <td id=\"T_ed13a_row1_col8\" class=\"data row1 col8\" >0.090357</td>\n",
       "      <td id=\"T_ed13a_row1_col9\" class=\"data row1 col9\" >0.131507</td>\n",
       "      <td id=\"T_ed13a_row1_col10\" class=\"data row1 col10\" >0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed13a_level0_row2\" class=\"row_heading level0 row2\" >I would like to sell you a house</th>\n",
       "      <td id=\"T_ed13a_row2_col0\" class=\"data row2 col0\" >0.025476</td>\n",
       "      <td id=\"T_ed13a_row2_col1\" class=\"data row2 col1\" >0.044178</td>\n",
       "      <td id=\"T_ed13a_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_ed13a_row2_col3\" class=\"data row2 col3\" >0.154773</td>\n",
       "      <td id=\"T_ed13a_row2_col4\" class=\"data row2 col4\" >0.083555</td>\n",
       "      <td id=\"T_ed13a_row2_col5\" class=\"data row2 col5\" >0.386736</td>\n",
       "      <td id=\"T_ed13a_row2_col6\" class=\"data row2 col6\" >0.017175</td>\n",
       "      <td id=\"T_ed13a_row2_col7\" class=\"data row2 col7\" >-0.006744</td>\n",
       "      <td id=\"T_ed13a_row2_col8\" class=\"data row2 col8\" >0.010857</td>\n",
       "      <td id=\"T_ed13a_row2_col9\" class=\"data row2 col9\" >0.025510</td>\n",
       "      <td id=\"T_ed13a_row2_col10\" class=\"data row2 col10\" >0.006353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed13a_level0_row3\" class=\"row_heading level0 row3\" >–Ø –ø—ã—Ç–∞—é—Å—å –∫—É–ø–∏—Ç—å –¥–∞—á—É</th>\n",
       "      <td id=\"T_ed13a_row3_col0\" class=\"data row3 col0\" >0.098335</td>\n",
       "      <td id=\"T_ed13a_row3_col1\" class=\"data row3 col1\" >0.035044</td>\n",
       "      <td id=\"T_ed13a_row3_col2\" class=\"data row3 col2\" >0.154773</td>\n",
       "      <td id=\"T_ed13a_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_ed13a_row3_col4\" class=\"data row3 col4\" >0.159519</td>\n",
       "      <td id=\"T_ed13a_row3_col5\" class=\"data row3 col5\" >0.064379</td>\n",
       "      <td id=\"T_ed13a_row3_col6\" class=\"data row3 col6\" >0.462397</td>\n",
       "      <td id=\"T_ed13a_row3_col7\" class=\"data row3 col7\" >0.092110</td>\n",
       "      <td id=\"T_ed13a_row3_col8\" class=\"data row3 col8\" >0.314708</td>\n",
       "      <td id=\"T_ed13a_row3_col9\" class=\"data row3 col9\" >0.327675</td>\n",
       "      <td id=\"T_ed13a_row3_col10\" class=\"data row3 col10\" >-0.119607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed13a_level0_row4\" class=\"row_heading level0 row4\" >J'aimerais vous louer un grand appartement</th>\n",
       "      <td id=\"T_ed13a_row4_col0\" class=\"data row4 col0\" >0.020435</td>\n",
       "      <td id=\"T_ed13a_row4_col1\" class=\"data row4 col1\" >-0.018194</td>\n",
       "      <td id=\"T_ed13a_row4_col2\" class=\"data row4 col2\" >0.083555</td>\n",
       "      <td id=\"T_ed13a_row4_col3\" class=\"data row4 col3\" >0.159519</td>\n",
       "      <td id=\"T_ed13a_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_ed13a_row4_col5\" class=\"data row4 col5\" >0.032253</td>\n",
       "      <td id=\"T_ed13a_row4_col6\" class=\"data row4 col6\" >0.365505</td>\n",
       "      <td id=\"T_ed13a_row4_col7\" class=\"data row4 col7\" >0.566635</td>\n",
       "      <td id=\"T_ed13a_row4_col8\" class=\"data row4 col8\" >0.172406</td>\n",
       "      <td id=\"T_ed13a_row4_col9\" class=\"data row4 col9\" >0.110118</td>\n",
       "      <td id=\"T_ed13a_row4_col10\" class=\"data row4 col10\" >-0.013743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed13a_level0_row5\" class=\"row_heading level0 row5\" >This is a wonderful investment opportunity</th>\n",
       "      <td id=\"T_ed13a_row5_col0\" class=\"data row5 col0\" >-0.065293</td>\n",
       "      <td id=\"T_ed13a_row5_col1\" class=\"data row5 col1\" >-0.004438</td>\n",
       "      <td id=\"T_ed13a_row5_col2\" class=\"data row5 col2\" >0.386736</td>\n",
       "      <td id=\"T_ed13a_row5_col3\" class=\"data row5 col3\" >0.064379</td>\n",
       "      <td id=\"T_ed13a_row5_col4\" class=\"data row5 col4\" >0.032253</td>\n",
       "      <td id=\"T_ed13a_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_ed13a_row5_col6\" class=\"data row5 col6\" >-0.030322</td>\n",
       "      <td id=\"T_ed13a_row5_col7\" class=\"data row5 col7\" >0.212230</td>\n",
       "      <td id=\"T_ed13a_row5_col8\" class=\"data row5 col8\" >0.023889</td>\n",
       "      <td id=\"T_ed13a_row5_col9\" class=\"data row5 col9\" >-0.002844</td>\n",
       "      <td id=\"T_ed13a_row5_col10\" class=\"data row5 col10\" >0.112804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed13a_level0_row6\" class=\"row_heading level0 row6\" >–≠—Ç–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π</th>\n",
       "      <td id=\"T_ed13a_row6_col0\" class=\"data row6 col0\" >0.035801</td>\n",
       "      <td id=\"T_ed13a_row6_col1\" class=\"data row6 col1\" >-0.078566</td>\n",
       "      <td id=\"T_ed13a_row6_col2\" class=\"data row6 col2\" >0.017175</td>\n",
       "      <td id=\"T_ed13a_row6_col3\" class=\"data row6 col3\" >0.462397</td>\n",
       "      <td id=\"T_ed13a_row6_col4\" class=\"data row6 col4\" >0.365505</td>\n",
       "      <td id=\"T_ed13a_row6_col5\" class=\"data row6 col5\" >-0.030322</td>\n",
       "      <td id=\"T_ed13a_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_ed13a_row6_col7\" class=\"data row6 col7\" >0.282414</td>\n",
       "      <td id=\"T_ed13a_row6_col8\" class=\"data row6 col8\" >0.267571</td>\n",
       "      <td id=\"T_ed13a_row6_col9\" class=\"data row6 col9\" >0.285873</td>\n",
       "      <td id=\"T_ed13a_row6_col10\" class=\"data row6 col10\" >-0.040309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed13a_level0_row7\" class=\"row_heading level0 row7\" >C'est une merveilleuse opportunit√© d'investissement</th>\n",
       "      <td id=\"T_ed13a_row7_col0\" class=\"data row7 col0\" >-0.062506</td>\n",
       "      <td id=\"T_ed13a_row7_col1\" class=\"data row7 col1\" >-0.011418</td>\n",
       "      <td id=\"T_ed13a_row7_col2\" class=\"data row7 col2\" >-0.006744</td>\n",
       "      <td id=\"T_ed13a_row7_col3\" class=\"data row7 col3\" >0.092110</td>\n",
       "      <td id=\"T_ed13a_row7_col4\" class=\"data row7 col4\" >0.566635</td>\n",
       "      <td id=\"T_ed13a_row7_col5\" class=\"data row7 col5\" >0.212230</td>\n",
       "      <td id=\"T_ed13a_row7_col6\" class=\"data row7 col6\" >0.282414</td>\n",
       "      <td id=\"T_ed13a_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "      <td id=\"T_ed13a_row7_col8\" class=\"data row7 col8\" >0.292651</td>\n",
       "      <td id=\"T_ed13a_row7_col9\" class=\"data row7 col9\" >0.187989</td>\n",
       "      <td id=\"T_ed13a_row7_col10\" class=\"data row7 col10\" >0.006793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed13a_level0_row8\" class=\"row_heading level0 row8\" >„Åì„Çå„ÅØÁ¥†Êô¥„Çâ„Åó„ÅÑÊäïË≥áÊ©ü‰ºö„Åß„Åô</th>\n",
       "      <td id=\"T_ed13a_row8_col0\" class=\"data row8 col0\" >0.027358</td>\n",
       "      <td id=\"T_ed13a_row8_col1\" class=\"data row8 col1\" >0.090357</td>\n",
       "      <td id=\"T_ed13a_row8_col2\" class=\"data row8 col2\" >0.010857</td>\n",
       "      <td id=\"T_ed13a_row8_col3\" class=\"data row8 col3\" >0.314708</td>\n",
       "      <td id=\"T_ed13a_row8_col4\" class=\"data row8 col4\" >0.172406</td>\n",
       "      <td id=\"T_ed13a_row8_col5\" class=\"data row8 col5\" >0.023889</td>\n",
       "      <td id=\"T_ed13a_row8_col6\" class=\"data row8 col6\" >0.267571</td>\n",
       "      <td id=\"T_ed13a_row8_col7\" class=\"data row8 col7\" >0.292651</td>\n",
       "      <td id=\"T_ed13a_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "      <td id=\"T_ed13a_row8_col9\" class=\"data row8 col9\" >0.577265</td>\n",
       "      <td id=\"T_ed13a_row8_col10\" class=\"data row8 col10\" >-0.100630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed13a_level0_row9\" class=\"row_heading level0 row9\" >ÈáéÁêÉ„ÅØ„ÅÇ„Å™„Åü„ÅåÊÄù„ÅÜ„Çà„Çä„ÇÇÈù¢ÁôΩ„ÅÑ„Åì„Å®„Åå„ÅÇ„Çä„Åæ„Åô</th>\n",
       "      <td id=\"T_ed13a_row9_col0\" class=\"data row9 col0\" >0.017622</td>\n",
       "      <td id=\"T_ed13a_row9_col1\" class=\"data row9 col1\" >0.131507</td>\n",
       "      <td id=\"T_ed13a_row9_col2\" class=\"data row9 col2\" >0.025510</td>\n",
       "      <td id=\"T_ed13a_row9_col3\" class=\"data row9 col3\" >0.327675</td>\n",
       "      <td id=\"T_ed13a_row9_col4\" class=\"data row9 col4\" >0.110118</td>\n",
       "      <td id=\"T_ed13a_row9_col5\" class=\"data row9 col5\" >-0.002844</td>\n",
       "      <td id=\"T_ed13a_row9_col6\" class=\"data row9 col6\" >0.285873</td>\n",
       "      <td id=\"T_ed13a_row9_col7\" class=\"data row9 col7\" >0.187989</td>\n",
       "      <td id=\"T_ed13a_row9_col8\" class=\"data row9 col8\" >0.577265</td>\n",
       "      <td id=\"T_ed13a_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "      <td id=\"T_ed13a_row9_col10\" class=\"data row9 col10\" >-0.098722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed13a_level0_row10\" class=\"row_heading level0 row10\" >Baseball can be interesting than you'd think</th>\n",
       "      <td id=\"T_ed13a_row10_col0\" class=\"data row10 col0\" >0.023445</td>\n",
       "      <td id=\"T_ed13a_row10_col1\" class=\"data row10 col1\" >0.016100</td>\n",
       "      <td id=\"T_ed13a_row10_col2\" class=\"data row10 col2\" >0.006353</td>\n",
       "      <td id=\"T_ed13a_row10_col3\" class=\"data row10 col3\" >-0.119607</td>\n",
       "      <td id=\"T_ed13a_row10_col4\" class=\"data row10 col4\" >-0.013743</td>\n",
       "      <td id=\"T_ed13a_row10_col5\" class=\"data row10 col5\" >0.112804</td>\n",
       "      <td id=\"T_ed13a_row10_col6\" class=\"data row10 col6\" >-0.040309</td>\n",
       "      <td id=\"T_ed13a_row10_col7\" class=\"data row10 col7\" >0.006793</td>\n",
       "      <td id=\"T_ed13a_row10_col8\" class=\"data row10 col8\" >-0.100630</td>\n",
       "      <td id=\"T_ed13a_row10_col9\" class=\"data row10 col9\" >-0.098722</td>\n",
       "      <td id=\"T_ed13a_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1376fbc40>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute similarities exactly the same as we did before!\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "# Turn into a dataframe\n",
    "pd.DataFrame(similarities,\n",
    "            index=sentences,\n",
    "            columns=sentences) \\\n",
    "            .style \\\n",
    "            .background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71a3019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36ad65db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d90cb_row0_col0, #T_d90cb_row1_col1, #T_d90cb_row2_col2, #T_d90cb_row3_col3, #T_d90cb_row4_col4, #T_d90cb_row5_col5, #T_d90cb_row6_col6, #T_d90cb_row7_col7, #T_d90cb_row8_col8, #T_d90cb_row9_col9, #T_d90cb_row10_col10 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d90cb_row0_col1, #T_d90cb_row1_col0 {\n",
       "  background-color: #93b5d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row0_col2, #T_d90cb_row1_col2, #T_d90cb_row2_col0, #T_d90cb_row2_col1 {\n",
       "  background-color: #e6e2ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row0_col3, #T_d90cb_row3_col0, #T_d90cb_row7_col10, #T_d90cb_row10_col7 {\n",
       "  background-color: #d4d4e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row0_col4, #T_d90cb_row1_col5, #T_d90cb_row1_col7, #T_d90cb_row4_col0, #T_d90cb_row5_col1, #T_d90cb_row7_col1 {\n",
       "  background-color: #f3edf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row0_col5, #T_d90cb_row5_col0 {\n",
       "  background-color: #faf2f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row0_col6, #T_d90cb_row0_col7, #T_d90cb_row6_col0, #T_d90cb_row7_col0 {\n",
       "  background-color: #faf3f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row0_col8, #T_d90cb_row8_col0 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row0_col9, #T_d90cb_row1_col6, #T_d90cb_row6_col1, #T_d90cb_row9_col0 {\n",
       "  background-color: #f4edf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row0_col10, #T_d90cb_row1_col4, #T_d90cb_row4_col1, #T_d90cb_row10_col0 {\n",
       "  background-color: #f0eaf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row1_col3, #T_d90cb_row3_col1 {\n",
       "  background-color: #c9cee4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row1_col8, #T_d90cb_row8_col1 {\n",
       "  background-color: #fcf4fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row1_col9, #T_d90cb_row2_col8, #T_d90cb_row8_col2, #T_d90cb_row9_col1 {\n",
       "  background-color: #e9e5f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row1_col10, #T_d90cb_row2_col7, #T_d90cb_row7_col2, #T_d90cb_row10_col1 {\n",
       "  background-color: #e4e1ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row2_col3, #T_d90cb_row3_col2 {\n",
       "  background-color: #7dacd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d90cb_row2_col4, #T_d90cb_row4_col2 {\n",
       "  background-color: #2182b9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d90cb_row2_col5, #T_d90cb_row5_col2 {\n",
       "  background-color: #e1dfed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row2_col6, #T_d90cb_row3_col8, #T_d90cb_row6_col2, #T_d90cb_row8_col3, #T_d90cb_row8_col10, #T_d90cb_row10_col8 {\n",
       "  background-color: #dad9ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row2_col9, #T_d90cb_row3_col7, #T_d90cb_row7_col3, #T_d90cb_row9_col2 {\n",
       "  background-color: #d5d5e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row2_col10, #T_d90cb_row6_col10, #T_d90cb_row10_col2, #T_d90cb_row10_col6 {\n",
       "  background-color: #d6d6e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row3_col4, #T_d90cb_row4_col3 {\n",
       "  background-color: #96b6d7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row3_col5, #T_d90cb_row5_col3 {\n",
       "  background-color: #d9d8ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row3_col6, #T_d90cb_row6_col3 {\n",
       "  background-color: #cacee5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row3_col9, #T_d90cb_row9_col3 {\n",
       "  background-color: #e7e3f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row3_col10, #T_d90cb_row10_col3 {\n",
       "  background-color: #e8e4f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row4_col5, #T_d90cb_row4_col7, #T_d90cb_row4_col9, #T_d90cb_row5_col4, #T_d90cb_row7_col4, #T_d90cb_row9_col4 {\n",
       "  background-color: #c5cce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row4_col6, #T_d90cb_row6_col4 {\n",
       "  background-color: #bbc7e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row4_col8, #T_d90cb_row8_col4 {\n",
       "  background-color: #c8cde4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row4_col10, #T_d90cb_row10_col4 {\n",
       "  background-color: #d3d4e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row5_col6, #T_d90cb_row6_col5 {\n",
       "  background-color: #034369;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d90cb_row5_col7, #T_d90cb_row7_col5 {\n",
       "  background-color: #034165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d90cb_row5_col8, #T_d90cb_row6_col8, #T_d90cb_row8_col5, #T_d90cb_row8_col6 {\n",
       "  background-color: #03456c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d90cb_row5_col9, #T_d90cb_row9_col5 {\n",
       "  background-color: #e5e1ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row5_col10, #T_d90cb_row10_col5 {\n",
       "  background-color: #d7d6e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row6_col7, #T_d90cb_row7_col6 {\n",
       "  background-color: #023f64;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d90cb_row6_col9, #T_d90cb_row7_col9, #T_d90cb_row9_col6, #T_d90cb_row9_col7 {\n",
       "  background-color: #e0deed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row7_col8, #T_d90cb_row8_col7 {\n",
       "  background-color: #034267;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d90cb_row8_col9, #T_d90cb_row9_col8 {\n",
       "  background-color: #e0dded;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d90cb_row9_col10, #T_d90cb_row10_col9 {\n",
       "  background-color: #045d92;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d90cb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d90cb_level0_col0\" class=\"col_heading level0 col0\" >Molly ate a fish</th>\n",
       "      <th id=\"T_d90cb_level0_col1\" class=\"col_heading level0 col1\" >Jen consumed a carp</th>\n",
       "      <th id=\"T_d90cb_level0_col2\" class=\"col_heading level0 col2\" >I would like to sell you a house</th>\n",
       "      <th id=\"T_d90cb_level0_col3\" class=\"col_heading level0 col3\" >–Ø –ø—ã—Ç–∞—é—Å—å –∫—É–ø–∏—Ç—å –¥–∞—á—É</th>\n",
       "      <th id=\"T_d90cb_level0_col4\" class=\"col_heading level0 col4\" >J'aimerais vous louer un grand appartement</th>\n",
       "      <th id=\"T_d90cb_level0_col5\" class=\"col_heading level0 col5\" >This is a wonderful investment opportunity</th>\n",
       "      <th id=\"T_d90cb_level0_col6\" class=\"col_heading level0 col6\" >–≠—Ç–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π</th>\n",
       "      <th id=\"T_d90cb_level0_col7\" class=\"col_heading level0 col7\" >C'est une merveilleuse opportunit√© d'investissement</th>\n",
       "      <th id=\"T_d90cb_level0_col8\" class=\"col_heading level0 col8\" >„Åì„Çå„ÅØÁ¥†Êô¥„Çâ„Åó„ÅÑÊäïË≥áÊ©ü‰ºö„Åß„Åô</th>\n",
       "      <th id=\"T_d90cb_level0_col9\" class=\"col_heading level0 col9\" >ÈáéÁêÉ„ÅØ„ÅÇ„Å™„Åü„ÅåÊÄù„ÅÜ„Çà„Çä„ÇÇÈù¢ÁôΩ„ÅÑ„Åì„Å®„Åå„ÅÇ„Çä„Åæ„Åô</th>\n",
       "      <th id=\"T_d90cb_level0_col10\" class=\"col_heading level0 col10\" >Baseball can be interesting than you'd think</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d90cb_level0_row0\" class=\"row_heading level0 row0\" >Molly ate a fish</th>\n",
       "      <td id=\"T_d90cb_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_d90cb_row0_col1\" class=\"data row0 col1\" >0.358347</td>\n",
       "      <td id=\"T_d90cb_row0_col2\" class=\"data row0 col2\" >0.058340</td>\n",
       "      <td id=\"T_d90cb_row0_col3\" class=\"data row0 col3\" >0.145439</td>\n",
       "      <td id=\"T_d90cb_row0_col4\" class=\"data row0 col4\" >-0.024103</td>\n",
       "      <td id=\"T_d90cb_row0_col5\" class=\"data row0 col5\" >-0.070145</td>\n",
       "      <td id=\"T_d90cb_row0_col6\" class=\"data row0 col6\" >-0.075333</td>\n",
       "      <td id=\"T_d90cb_row0_col7\" class=\"data row0 col7\" >-0.073496</td>\n",
       "      <td id=\"T_d90cb_row0_col8\" class=\"data row0 col8\" >-0.111467</td>\n",
       "      <td id=\"T_d90cb_row0_col9\" class=\"data row0 col9\" >-0.025614</td>\n",
       "      <td id=\"T_d90cb_row0_col10\" class=\"data row0 col10\" >0.001549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d90cb_level0_row1\" class=\"row_heading level0 row1\" >Jen consumed a carp</th>\n",
       "      <td id=\"T_d90cb_row1_col0\" class=\"data row1 col0\" >0.358347</td>\n",
       "      <td id=\"T_d90cb_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_d90cb_row1_col2\" class=\"data row1 col2\" >0.059195</td>\n",
       "      <td id=\"T_d90cb_row1_col3\" class=\"data row1 col3\" >0.190241</td>\n",
       "      <td id=\"T_d90cb_row1_col4\" class=\"data row1 col4\" >-0.001941</td>\n",
       "      <td id=\"T_d90cb_row1_col5\" class=\"data row1 col5\" >-0.024359</td>\n",
       "      <td id=\"T_d90cb_row1_col6\" class=\"data row1 col6\" >-0.024816</td>\n",
       "      <td id=\"T_d90cb_row1_col7\" class=\"data row1 col7\" >-0.023295</td>\n",
       "      <td id=\"T_d90cb_row1_col8\" class=\"data row1 col8\" >-0.087019</td>\n",
       "      <td id=\"T_d90cb_row1_col9\" class=\"data row1 col9\" >0.040799</td>\n",
       "      <td id=\"T_d90cb_row1_col10\" class=\"data row1 col10\" >0.067243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d90cb_level0_row2\" class=\"row_heading level0 row2\" >I would like to sell you a house</th>\n",
       "      <td id=\"T_d90cb_row2_col0\" class=\"data row2 col0\" >0.058340</td>\n",
       "      <td id=\"T_d90cb_row2_col1\" class=\"data row2 col1\" >0.059195</td>\n",
       "      <td id=\"T_d90cb_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_d90cb_row2_col3\" class=\"data row2 col3\" >0.418692</td>\n",
       "      <td id=\"T_d90cb_row2_col4\" class=\"data row2 col4\" >0.642746</td>\n",
       "      <td id=\"T_d90cb_row2_col5\" class=\"data row2 col5\" >0.081795</td>\n",
       "      <td id=\"T_d90cb_row2_col6\" class=\"data row2 col6\" >0.118611</td>\n",
       "      <td id=\"T_d90cb_row2_col7\" class=\"data row2 col7\" >0.067805</td>\n",
       "      <td id=\"T_d90cb_row2_col8\" class=\"data row2 col8\" >0.042560</td>\n",
       "      <td id=\"T_d90cb_row2_col9\" class=\"data row2 col9\" >0.144491</td>\n",
       "      <td id=\"T_d90cb_row2_col10\" class=\"data row2 col10\" >0.139300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d90cb_level0_row3\" class=\"row_heading level0 row3\" >–Ø –ø—ã—Ç–∞—é—Å—å –∫—É–ø–∏—Ç—å –¥–∞—á—É</th>\n",
       "      <td id=\"T_d90cb_row3_col0\" class=\"data row3 col0\" >0.145439</td>\n",
       "      <td id=\"T_d90cb_row3_col1\" class=\"data row3 col1\" >0.190241</td>\n",
       "      <td id=\"T_d90cb_row3_col2\" class=\"data row3 col2\" >0.418692</td>\n",
       "      <td id=\"T_d90cb_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_d90cb_row3_col4\" class=\"data row3 col4\" >0.351605</td>\n",
       "      <td id=\"T_d90cb_row3_col5\" class=\"data row3 col5\" >0.120679</td>\n",
       "      <td id=\"T_d90cb_row3_col6\" class=\"data row3 col6\" >0.184644</td>\n",
       "      <td id=\"T_d90cb_row3_col7\" class=\"data row3 col7\" >0.144633</td>\n",
       "      <td id=\"T_d90cb_row3_col8\" class=\"data row3 col8\" >0.115598</td>\n",
       "      <td id=\"T_d90cb_row3_col9\" class=\"data row3 col9\" >0.050505</td>\n",
       "      <td id=\"T_d90cb_row3_col10\" class=\"data row3 col10\" >0.046084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d90cb_level0_row4\" class=\"row_heading level0 row4\" >J'aimerais vous louer un grand appartement</th>\n",
       "      <td id=\"T_d90cb_row4_col0\" class=\"data row4 col0\" >-0.024103</td>\n",
       "      <td id=\"T_d90cb_row4_col1\" class=\"data row4 col1\" >-0.001941</td>\n",
       "      <td id=\"T_d90cb_row4_col2\" class=\"data row4 col2\" >0.642746</td>\n",
       "      <td id=\"T_d90cb_row4_col3\" class=\"data row4 col3\" >0.351605</td>\n",
       "      <td id=\"T_d90cb_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_d90cb_row4_col5\" class=\"data row4 col5\" >0.203307</td>\n",
       "      <td id=\"T_d90cb_row4_col6\" class=\"data row4 col6\" >0.238716</td>\n",
       "      <td id=\"T_d90cb_row4_col7\" class=\"data row4 col7\" >0.204762</td>\n",
       "      <td id=\"T_d90cb_row4_col8\" class=\"data row4 col8\" >0.195163</td>\n",
       "      <td id=\"T_d90cb_row4_col9\" class=\"data row4 col9\" >0.201317</td>\n",
       "      <td id=\"T_d90cb_row4_col10\" class=\"data row4 col10\" >0.151998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d90cb_level0_row5\" class=\"row_heading level0 row5\" >This is a wonderful investment opportunity</th>\n",
       "      <td id=\"T_d90cb_row5_col0\" class=\"data row5 col0\" >-0.070145</td>\n",
       "      <td id=\"T_d90cb_row5_col1\" class=\"data row5 col1\" >-0.024359</td>\n",
       "      <td id=\"T_d90cb_row5_col2\" class=\"data row5 col2\" >0.081795</td>\n",
       "      <td id=\"T_d90cb_row5_col3\" class=\"data row5 col3\" >0.120679</td>\n",
       "      <td id=\"T_d90cb_row5_col4\" class=\"data row5 col4\" >0.203307</td>\n",
       "      <td id=\"T_d90cb_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_d90cb_row5_col6\" class=\"data row5 col6\" >0.953561</td>\n",
       "      <td id=\"T_d90cb_row5_col7\" class=\"data row5 col7\" >0.964282</td>\n",
       "      <td id=\"T_d90cb_row5_col8\" class=\"data row5 col8\" >0.945246</td>\n",
       "      <td id=\"T_d90cb_row5_col9\" class=\"data row5 col9\" >0.062618</td>\n",
       "      <td id=\"T_d90cb_row5_col10\" class=\"data row5 col10\" >0.133220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d90cb_level0_row6\" class=\"row_heading level0 row6\" >–≠—Ç–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π</th>\n",
       "      <td id=\"T_d90cb_row6_col0\" class=\"data row6 col0\" >-0.075333</td>\n",
       "      <td id=\"T_d90cb_row6_col1\" class=\"data row6 col1\" >-0.024816</td>\n",
       "      <td id=\"T_d90cb_row6_col2\" class=\"data row6 col2\" >0.118611</td>\n",
       "      <td id=\"T_d90cb_row6_col3\" class=\"data row6 col3\" >0.184644</td>\n",
       "      <td id=\"T_d90cb_row6_col4\" class=\"data row6 col4\" >0.238716</td>\n",
       "      <td id=\"T_d90cb_row6_col5\" class=\"data row6 col5\" >0.953561</td>\n",
       "      <td id=\"T_d90cb_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_d90cb_row6_col7\" class=\"data row6 col7\" >0.968368</td>\n",
       "      <td id=\"T_d90cb_row6_col8\" class=\"data row6 col8\" >0.944719</td>\n",
       "      <td id=\"T_d90cb_row6_col9\" class=\"data row6 col9\" >0.084221</td>\n",
       "      <td id=\"T_d90cb_row6_col10\" class=\"data row6 col10\" >0.136699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d90cb_level0_row7\" class=\"row_heading level0 row7\" >C'est une merveilleuse opportunit√© d'investissement</th>\n",
       "      <td id=\"T_d90cb_row7_col0\" class=\"data row7 col0\" >-0.073496</td>\n",
       "      <td id=\"T_d90cb_row7_col1\" class=\"data row7 col1\" >-0.023295</td>\n",
       "      <td id=\"T_d90cb_row7_col2\" class=\"data row7 col2\" >0.067805</td>\n",
       "      <td id=\"T_d90cb_row7_col3\" class=\"data row7 col3\" >0.144633</td>\n",
       "      <td id=\"T_d90cb_row7_col4\" class=\"data row7 col4\" >0.204762</td>\n",
       "      <td id=\"T_d90cb_row7_col5\" class=\"data row7 col5\" >0.964282</td>\n",
       "      <td id=\"T_d90cb_row7_col6\" class=\"data row7 col6\" >0.968368</td>\n",
       "      <td id=\"T_d90cb_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "      <td id=\"T_d90cb_row7_col8\" class=\"data row7 col8\" >0.959357</td>\n",
       "      <td id=\"T_d90cb_row7_col9\" class=\"data row7 col9\" >0.086458</td>\n",
       "      <td id=\"T_d90cb_row7_col10\" class=\"data row7 col10\" >0.146568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d90cb_level0_row8\" class=\"row_heading level0 row8\" >„Åì„Çå„ÅØÁ¥†Êô¥„Çâ„Åó„ÅÑÊäïË≥áÊ©ü‰ºö„Åß„Åô</th>\n",
       "      <td id=\"T_d90cb_row8_col0\" class=\"data row8 col0\" >-0.111467</td>\n",
       "      <td id=\"T_d90cb_row8_col1\" class=\"data row8 col1\" >-0.087019</td>\n",
       "      <td id=\"T_d90cb_row8_col2\" class=\"data row8 col2\" >0.042560</td>\n",
       "      <td id=\"T_d90cb_row8_col3\" class=\"data row8 col3\" >0.115598</td>\n",
       "      <td id=\"T_d90cb_row8_col4\" class=\"data row8 col4\" >0.195163</td>\n",
       "      <td id=\"T_d90cb_row8_col5\" class=\"data row8 col5\" >0.945246</td>\n",
       "      <td id=\"T_d90cb_row8_col6\" class=\"data row8 col6\" >0.944719</td>\n",
       "      <td id=\"T_d90cb_row8_col7\" class=\"data row8 col7\" >0.959357</td>\n",
       "      <td id=\"T_d90cb_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "      <td id=\"T_d90cb_row8_col9\" class=\"data row8 col9\" >0.091451</td>\n",
       "      <td id=\"T_d90cb_row8_col10\" class=\"data row8 col10\" >0.115392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d90cb_level0_row9\" class=\"row_heading level0 row9\" >ÈáéÁêÉ„ÅØ„ÅÇ„Å™„Åü„ÅåÊÄù„ÅÜ„Çà„Çä„ÇÇÈù¢ÁôΩ„ÅÑ„Åì„Å®„Åå„ÅÇ„Çä„Åæ„Åô</th>\n",
       "      <td id=\"T_d90cb_row9_col0\" class=\"data row9 col0\" >-0.025614</td>\n",
       "      <td id=\"T_d90cb_row9_col1\" class=\"data row9 col1\" >0.040799</td>\n",
       "      <td id=\"T_d90cb_row9_col2\" class=\"data row9 col2\" >0.144491</td>\n",
       "      <td id=\"T_d90cb_row9_col3\" class=\"data row9 col3\" >0.050505</td>\n",
       "      <td id=\"T_d90cb_row9_col4\" class=\"data row9 col4\" >0.201317</td>\n",
       "      <td id=\"T_d90cb_row9_col5\" class=\"data row9 col5\" >0.062618</td>\n",
       "      <td id=\"T_d90cb_row9_col6\" class=\"data row9 col6\" >0.084221</td>\n",
       "      <td id=\"T_d90cb_row9_col7\" class=\"data row9 col7\" >0.086458</td>\n",
       "      <td id=\"T_d90cb_row9_col8\" class=\"data row9 col8\" >0.091451</td>\n",
       "      <td id=\"T_d90cb_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "      <td id=\"T_d90cb_row9_col10\" class=\"data row9 col10\" >0.839617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d90cb_level0_row10\" class=\"row_heading level0 row10\" >Baseball can be interesting than you'd think</th>\n",
       "      <td id=\"T_d90cb_row10_col0\" class=\"data row10 col0\" >0.001549</td>\n",
       "      <td id=\"T_d90cb_row10_col1\" class=\"data row10 col1\" >0.067243</td>\n",
       "      <td id=\"T_d90cb_row10_col2\" class=\"data row10 col2\" >0.139300</td>\n",
       "      <td id=\"T_d90cb_row10_col3\" class=\"data row10 col3\" >0.046084</td>\n",
       "      <td id=\"T_d90cb_row10_col4\" class=\"data row10 col4\" >0.151998</td>\n",
       "      <td id=\"T_d90cb_row10_col5\" class=\"data row10 col5\" >0.133220</td>\n",
       "      <td id=\"T_d90cb_row10_col6\" class=\"data row10 col6\" >0.136699</td>\n",
       "      <td id=\"T_d90cb_row10_col7\" class=\"data row10 col7\" >0.146568</td>\n",
       "      <td id=\"T_d90cb_row10_col8\" class=\"data row10 col8\" >0.115392</td>\n",
       "      <td id=\"T_d90cb_row10_col9\" class=\"data row10 col9\" >0.839617</td>\n",
       "      <td id=\"T_d90cb_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1376a7400>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute similarities exactly the same as we did before!\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "# Turn into a dataframe\n",
    "pd.DataFrame(similarities,\n",
    "            index=sentences,\n",
    "            columns=sentences) \\\n",
    "            .style \\\n",
    "            .background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186c699",
   "metadata": {},
   "source": [
    "### Searching through documents with semantic search\n",
    "\n",
    "What does this allow you to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5eafd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('ai-report.pdf')\n",
    "docs = loader.load_and_split()\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53cef004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name='paraphrase-multilingual-MiniLM-L12-v2')\n",
    "db = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "06f009ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(lc_kwargs={'page_content': '7\\n12 Cultural resistance and fears of job displacement and scepticism of AI technologies \\ncannot be discounted. \\n13 Across the board, respondents noted that mitigating AI integration challenges requires \\nbridging knowledge gaps among various teams in the newsroom. Similarly, cross-\\ndepartment collaboration was seen as necessary for achieving effective AI adoption.\\n14 The challenge of keeping pace with the rapid evolution of AI was consistently \\nmentioned throughout the survey.\\n15 About 40% of respondents said their approach to AI has not changed over the past \\nfew years, either because they are still in the beginning of their AI journey or because \\nAI integration remains limited in their newsrooms. Concurrently, around a 1/4 said \\ntheir organisation‚Äôs approach to AI has evolved; they have gained hands-on experience \\nthat helps them think more realistically about AI.\\n16 More than 60% of respondents are concerned about the ethical implications of AI \\nintegration for editorial quality and other aspects of journalism. Journalists are trying \\nto figure out how to integrate AI technologies in their work upholding journalistic \\nvalues like accuracy, fairness, and transparency. \\n17 Respondents called for transparency from the designers of AI systems and \\ntechnology companies, and the users, namely newsrooms, with their audiences. \\n18 Journalists and mediamakers continued to stress the need for a ‚Äòhuman in the loop \\napproach,‚Äô in line with the results in our 2019 survey.\\n19 There are fears that AI technologies would further commercialise journalism,  \\nboosting poor quality and polarising content, leading to a further decline in public  \\ntrust in journalism.\\n20 Tech companies are driving innovation in AI and other technologies, but survey \\nparticipants voiced concerns about their profit-driven nature, the concentration of \\npower they enjoy, and their lack of transparency.\\n21 Around 80% of the respondents expect a larger role for AI in their newsrooms  \\nin the future. \\n22 Survey participants expect AI to influence four main areas:\\n 1  Fact-checking and disinformation analysis\\n 2  Content personalisation and automation\\n 3  Text summarisation and generation\\n 4   Using chatbots to conduct preliminary interviews and gauge public sentiment  \\non issues', 'metadata': {'source': 'ai-report.pdf', 'page': 7}}, page_content='7\\n12 Cultural resistance and fears of job displacement and scepticism of AI technologies \\ncannot be discounted. \\n13 Across the board, respondents noted that mitigating AI integration challenges requires \\nbridging knowledge gaps among various teams in the newsroom. Similarly, cross-\\ndepartment collaboration was seen as necessary for achieving effective AI adoption.\\n14 The challenge of keeping pace with the rapid evolution of AI was consistently \\nmentioned throughout the survey.\\n15 About 40% of respondents said their approach to AI has not changed over the past \\nfew years, either because they are still in the beginning of their AI journey or because \\nAI integration remains limited in their newsrooms. Concurrently, around a 1/4 said \\ntheir organisation‚Äôs approach to AI has evolved; they have gained hands-on experience \\nthat helps them think more realistically about AI.\\n16 More than 60% of respondents are concerned about the ethical implications of AI \\nintegration for editorial quality and other aspects of journalism. Journalists are trying \\nto figure out how to integrate AI technologies in their work upholding journalistic \\nvalues like accuracy, fairness, and transparency. \\n17 Respondents called for transparency from the designers of AI systems and \\ntechnology companies, and the users, namely newsrooms, with their audiences. \\n18 Journalists and mediamakers continued to stress the need for a ‚Äòhuman in the loop \\napproach,‚Äô in line with the results in our 2019 survey.\\n19 There are fears that AI technologies would further commercialise journalism,  \\nboosting poor quality and polarising content, leading to a further decline in public  \\ntrust in journalism.\\n20 Tech companies are driving innovation in AI and other technologies, but survey \\nparticipants voiced concerns about their profit-driven nature, the concentration of \\npower they enjoy, and their lack of transparency.\\n21 Around 80% of the respondents expect a larger role for AI in their newsrooms  \\nin the future. \\n22 Survey participants expect AI to influence four main areas:\\n 1  Fact-checking and disinformation analysis\\n 2  Content personalisation and automation\\n 3  Text summarisation and generation\\n 4   Using chatbots to conduct preliminary interviews and gauge public sentiment  \\non issues', metadata={'source': 'ai-report.pdf', 'page': 7}),\n",
       " Document(lc_kwargs={'page_content': '5555AI could become a crossroad and an insurmountable hurdle for news \\norganisations that do not realise that AI is just a new aspect of the constant \\nprogress of digital transformation. ‚Ä¶ some news organisations have been very slow \\nin digitising their business models (or haven‚Äôt even succeeded in doing so) ‚Äì now \\nthe next shock is just around the corner. \\nSeveral newsrooms expected AI to make them ‚Äúleaner,‚Äù as an increasing number of tasks \\nbecome automated:\\nIt may mean job losses because the work is currently being done by say five \\npeople, and may only need one person. \\nIt will have a drastic impact‚Ä¶If machines can write stories, edit them and \\ndistribute them, it follows that newsrooms have to be leaner. \\nOthers said that AI will not ‚Äúreplace jobs.‚Äù Rather, AI will redefine the role of journalists; \\n‚Äústeering AI‚Ä¶ requires new competencies and new functions.‚Äù \\nAnother respondent said: \\nWe believe AI isn‚Äôt a threat to jobs. But people who learn to effectively use AI to \\nleverage their work will be in demand, and soon many roles will expect people to be \\nable to use these tools. \\nThe need for a balancing act between tech and journalism, a theme that emerged in our \\n2019 survey, remains imperative to a future where AI technologies are leveraged to serve \\njournalism and its mission:\\nIt will involve a rethinking of the entire workflow and, at least during the adoption \\nphase, additional work to adapt to this new approach. There will be more \\ncollaboration and intersection between journalistic and technical figures. \\nOthers worried that the reliance on AI technologies will undermine journalistic values, for \\ninstance by pushing polarising content. This in turn would reduce public trust in journalism, \\nwhich many think is in decline as noted prev iously:', 'metadata': {'source': 'ai-report.pdf', 'page': 55}}, page_content='5555AI could become a crossroad and an insurmountable hurdle for news \\norganisations that do not realise that AI is just a new aspect of the constant \\nprogress of digital transformation. ‚Ä¶ some news organisations have been very slow \\nin digitising their business models (or haven‚Äôt even succeeded in doing so) ‚Äì now \\nthe next shock is just around the corner. \\nSeveral newsrooms expected AI to make them ‚Äúleaner,‚Äù as an increasing number of tasks \\nbecome automated:\\nIt may mean job losses because the work is currently being done by say five \\npeople, and may only need one person. \\nIt will have a drastic impact‚Ä¶If machines can write stories, edit them and \\ndistribute them, it follows that newsrooms have to be leaner. \\nOthers said that AI will not ‚Äúreplace jobs.‚Äù Rather, AI will redefine the role of journalists; \\n‚Äústeering AI‚Ä¶ requires new competencies and new functions.‚Äù \\nAnother respondent said: \\nWe believe AI isn‚Äôt a threat to jobs. But people who learn to effectively use AI to \\nleverage their work will be in demand, and soon many roles will expect people to be \\nable to use these tools. \\nThe need for a balancing act between tech and journalism, a theme that emerged in our \\n2019 survey, remains imperative to a future where AI technologies are leveraged to serve \\njournalism and its mission:\\nIt will involve a rethinking of the entire workflow and, at least during the adoption \\nphase, additional work to adapt to this new approach. There will be more \\ncollaboration and intersection between journalistic and technical figures. \\nOthers worried that the reliance on AI technologies will undermine journalistic values, for \\ninstance by pushing polarising content. This in turn would reduce public trust in journalism, \\nwhich many think is in decline as noted prev iously:', metadata={'source': 'ai-report.pdf', 'page': 55}),\n",
       " Document(lc_kwargs={'page_content': 'Other than language challenges, very few respondents mentioned failures in specific \\nAI-applications. However, when discussed, some respondents attributed any failures to \\norganisational issues, rather than to technical limitations: \\nThe biggest failure has been slow progression on already identified use cases \\nbecause of organisational issues, lack of focus and resources. \\nFor some of our third-party available machine learning offerings, we found that \\nwe didn‚Äôt have a strong onboarding process or clear explanations, so uptake has \\nbeen slower than anticipated. \\nOne respondent explained how their organisation decided to discontinue their work on \\nan ‚Äúautomated service to write short stories about companies performance in the stock \\nmarket,‚Äù because it did not gain popularity with the audience:\\n[It] did not create enough user value (the users rather looked at the stock graph), \\nand when the pandemic hit and all stocks went south, our thresholds were reached \\nfor almost all companies spamming our users. \\n24\\n24', 'metadata': {'source': 'ai-report.pdf', 'page': 24}}, page_content='Other than language challenges, very few respondents mentioned failures in specific \\nAI-applications. However, when discussed, some respondents attributed any failures to \\norganisational issues, rather than to technical limitations: \\nThe biggest failure has been slow progression on already identified use cases \\nbecause of organisational issues, lack of focus and resources. \\nFor some of our third-party available machine learning offerings, we found that \\nwe didn‚Äôt have a strong onboarding process or clear explanations, so uptake has \\nbeen slower than anticipated. \\nOne respondent explained how their organisation decided to discontinue their work on \\nan ‚Äúautomated service to write short stories about companies performance in the stock \\nmarket,‚Äù because it did not gain popularity with the audience:\\n[It] did not create enough user value (the users rather looked at the stock graph), \\nand when the pandemic hit and all stocks went south, our thresholds were reached \\nfor almost all companies spamming our users. \\n24\\n24', metadata={'source': 'ai-report.pdf', 'page': 24}),\n",
       " Document(lc_kwargs={'page_content': '33Newsrooms were not entirely sure which skillset(s) to look for in technical personnel . \\nNewsrooms with several years of experience with AI integration in the newsroom \\nmentioned specifically the challenge of achieving compatibility and interoperability with \\nexisting systems and platforms: \\nThe main blocker to deploying an ML-based tagging system, for example, is \\ntechnical; it needs to be integrated with other systems. \\nTested tools have to be implemented into current business structures, which \\nrequires quite a lot of development and testing. \\nThese responses highlight the huge strides some newsrooms have made in AI adoption \\nat an institutional level. In our 2019 report, many of the respondents, including early \\nadopters, were at the beginning of their AI journeys. Technical challenges focused on \\nwhich projects to prioritise, how to demystify AI and providing general AI literacy training \\nto personnel.\\nThe responses also highlight a disparity between smaller, emerging newsrooms in Global \\nSouth countries on the one hand, and large, well-resourced, more experienced news \\norganisations in Global North countries. While responses by the former focused on finding \\nthe resources to hire the technical experience needed, the latter have already deployed AI \\ntechnologies in various areas and are now focused on achieving interoperability:\\nWe are a mid-sized regional nonprofit startup with a strong engineering team \\nand an innovative organisational culture‚Ä¶ But, we have nowhere near the technical \\npower of large national organisations. \\nMitigating AI integration challenges goes beyond hiring the right technical staff. It \\nrequires bridging knowledge gaps that exist among various teams in the newsroom, \\na challenge that is more consistent across the board. Responses reflected a need to \\nenhance AI literacy and technical skills among journalists and technical staff alike: \\n[We] have varying levels of understanding on what AI is. In a team of about 20 \\npeople, less than a ¬º have training on it and we have yet to get everybody up to \\nspeed. I think my organisation will be equipped to take advantage of its potential \\nonce we are all on the same page.', 'metadata': {'source': 'ai-report.pdf', 'page': 33}}, page_content='33Newsrooms were not entirely sure which skillset(s) to look for in technical personnel . \\nNewsrooms with several years of experience with AI integration in the newsroom \\nmentioned specifically the challenge of achieving compatibility and interoperability with \\nexisting systems and platforms: \\nThe main blocker to deploying an ML-based tagging system, for example, is \\ntechnical; it needs to be integrated with other systems. \\nTested tools have to be implemented into current business structures, which \\nrequires quite a lot of development and testing. \\nThese responses highlight the huge strides some newsrooms have made in AI adoption \\nat an institutional level. In our 2019 report, many of the respondents, including early \\nadopters, were at the beginning of their AI journeys. Technical challenges focused on \\nwhich projects to prioritise, how to demystify AI and providing general AI literacy training \\nto personnel.\\nThe responses also highlight a disparity between smaller, emerging newsrooms in Global \\nSouth countries on the one hand, and large, well-resourced, more experienced news \\norganisations in Global North countries. While responses by the former focused on finding \\nthe resources to hire the technical experience needed, the latter have already deployed AI \\ntechnologies in various areas and are now focused on achieving interoperability:\\nWe are a mid-sized regional nonprofit startup with a strong engineering team \\nand an innovative organisational culture‚Ä¶ But, we have nowhere near the technical \\npower of large national organisations. \\nMitigating AI integration challenges goes beyond hiring the right technical staff. It \\nrequires bridging knowledge gaps that exist among various teams in the newsroom, \\na challenge that is more consistent across the board. Responses reflected a need to \\nenhance AI literacy and technical skills among journalists and technical staff alike: \\n[We] have varying levels of understanding on what AI is. In a team of about 20 \\npeople, less than a ¬º have training on it and we have yet to get everybody up to \\nspeed. I think my organisation will be equipped to take advantage of its potential \\nonce we are all on the same page.', metadata={'source': 'ai-report.pdf', 'page': 33})]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"losing jobs\", k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5037ed4f",
   "metadata": {},
   "source": [
    "### Specifying details\n",
    "\n",
    "Let's get a little more specific!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d8af6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader('hungarian-folktales.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b7130677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n",
      "Exiting: Cleaning up .chroma directory\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name='paraphrase-multilingual-MiniLM-L12-v2')\n",
    "db = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3e518686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eltelt az egy h√≥nap, el√©rkezett az esk√ºv≈ë napja, ott volt a sok vend√©g,\n",
      "k√∂zt√∂k a boltos is, csak a v≈ëleg√©nyt meg a menyasszonyt nem lehetett\n",
      "l√°tni. Bek√∂vetkezett az eb√©d ideje is, mindny√°jan v√≠gan √ºltek le az\n",
      "asztalhoz, elkezdtek enni. Az volt a szok√°s a gr√≥f h√°z√°n√°l, hogy minden\n",
      "embernek egy kis k√ºl√∂n t√°lban vitt√©k az √©telt; a boltos amint a maga\n",
      "t√°lj√°b√≥l szedett levest, h√°t csak alig tudta megenni, olyan s√≥talan\n",
      "volt, n√©zett k√∂r√ºl s√≥ ut√°n, de nem volt az eg√©sz asztalon; a m√°sodik\n",
      "√©tel m√©g s√≥talanabb volt, a harmadik meg m√°r olyan volt, hogy hozz√° se‚Äô\n",
      "tudott ny√∫lni. K√©rdezt√©k t≈ële hogy m√©rt nem eszik? t√°n valami baja van\n",
      "az √©telnek? amint ott vallatt√°k, esz√©be jutott a ly√°nya, hogy az neki\n",
      "azt mondta, hogy √∫gy szereti, mint a s√≥t, elkezdett s√≠rni; k√©rdezt√©k\n",
      "azt√°n t≈ële, hogy m√©rt s√≠r, akkor elbesz√©lt mindent, hogy volt neki egy\n",
      "ly√°nya, az egyszer neki azt mondta, hogy √∫gy szereti mint a s√≥t, ≈ë\n",
      "megharagudott √©rte, elkergette a h√°z√°t√≥l, l√°m most l√°tja, hogy milyen\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "matches = db.similarity_search(\"weddings at a festival with loud music\", k=1)\n",
    "\n",
    "for match in matches:\n",
    "    print(match.page_content)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df04a45f",
   "metadata": {},
   "source": [
    "## Retrieval-augmented generation (smart chatbots)\n",
    "\n",
    "Find relevant passages, send them to your chatbot along with your question.\n",
    "\n",
    "::: {.callout-note appearance=\"simple\"}\n",
    "You can improve performance by generating potential answers, then also including things similar to potential answers.\n",
    ":::\n",
    "\n",
    "There are a lot of places things can go wrong: segmented poorly or missing context, non-useful embeddings, question not being answered incorrectly. It's probably best if you just use semantic search to get results and read them yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34537351",
   "metadata": {},
   "source": [
    "## Expanding your skillset\n",
    "\n",
    "Lorem ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2637c",
   "metadata": {},
   "source": [
    "## Contact me\n",
    "\n",
    "Feel free to reach out ‚Äì I'm more than happy to provide ideas, guidance, lectures, etc etc etc. You can find me via email at [js4571@columbia.edu](mailto:js4571@columbia.edu) or on Twitter at [@dangerscarf](https://twitter.com/dangerscarf). I also run two data journalism programs at Columbia: the 12-month [Data Journalism MS](https://journalism.columbia.edu/ms-data-journalism) and the [Lede Program](https://ledeprogram.com/), a summer intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491430f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
